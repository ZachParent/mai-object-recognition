# problems with running
- bruno's machine
	- requires < TF 2.11 for GPU efficiency
	- runs but caps out at 50mins with OOM error
		- probably not a real hardware limitation
	- bruno will be busy Friday 7/3->Tuesday 11/3
	- we should not rely on this
- mac pip version for TF is not available
	- sheena and zach have struggled to adapt the requirements
	- TF 2.10.1 is not a recognized version for us
		- perhaps it's a Mac M1 issue
- code provided includes deprecated function
	- **ImageDataGenerator**
# goals
## **get shared dependencies working for everyone**
- this may involve updating the code to use more modern TF API
- we will not prioritize bruno's machine
## **find an environment for running**
1. google colab
2. docker container remote
	- e.g. digital ocean
3. docker container local
# tasks
1. **requirements.txt**
2. **solve ImageDataGenerator**
# plan
- check colab runs modified professor notebook
- split professor notebook into src .py files
	- main.ipynb
	- config.py
		- `epochs = 12`
	- experiments_config.py
		- `[{model: VGG, activation_function: 'ReLU', ...}, {model: AlexNet, activation_function: '...'}]`
	- models.py
		- `AlexNet = ...`
		- `models= [AlexNet, ]`
	- train.py
		- `for epoch in range(epochs):...`
	- metrics.py
	- load_data.py
		- can reference augmentation.py
		- use pipeline
	- augmentation.py
## example experiment config
```python
experiments = [{
    'name': 'comparing activation functions',
    'configs': [{
        'name': 'activation_relu',
        'activation': 'relu',
        'batch_size': 32,
        'epochs': 10,
        'learning_rate': 0.001,
        'optimizer': 'adam',
    },
    {
        'name': 'activation_tanh',
        'activation': 'tanh',
        'batch_size': 32,
        'epochs': 10,
        'learning_rate': 0.001,
        'optimizer': 'adam',
    }]
},
{   
    'name': 'comparing batch size',
    'configs': [{
        'name': 'batch_size_32',
        'batch_size': 32,
        'epochs': 10,
        'learning_rate': 0.001,
        'optimizer': 'adam',
    },
    {
        'name': 'batch_size_64',
        'batch_size': 64,
        'epochs': 10,
        'learning_rate': 0.001,
        'optimizer': 'adam',
    }]
},
{
    'name': 'comparing_learning_rate',
    'configs': [{
        'name': 'learning_rate_0.001',
        'batch_size': 32,
        'epochs': 10,
        'learning_rate': 0.001,
        'optimizer': 'adam',
    },
    {
        'name': 'learning_rate_0.0001',
        'batch_size': 32,
        'epochs': 10,
        'learning_rate': 0.0001,
        'optimizer': 'adam',
    }]
}]
```