{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDqDj4kC9sFJ"
   },
   "source": [
    "# Master course in Object Recognition\n",
    "## Practice 1\n",
    "\n",
    "### Title: Deep learning advanced architectures\n",
    "\n",
    "The goal is to practice advanced deep learning architectures for multi-label classification in [Pascal VOC dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html). We specifically check ResNet50, Inception and MobileNet. We will see 1) how pretrained ResNet50 on imagenet performs on multi-label images, 2) how to modify classification head and 3) implementation of F1 metric.\n",
    "\n",
    "### NOTES\n",
    "\n",
    "- Hyperparameters are modifiable,\n",
    "- The dataset is PASCAL VOC 2012,\n",
    "- The code uses the KERAS library,\n",
    "- The code can run in google colab.\n",
    "- How to finetune on a pretrained model not included (i.e. freeze the pretrained network and train the head, then finetune everything),\n",
    "- No validation set has been defined. The test and validation sets are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 17:30:47.036727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741368647.055656  257261 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741368647.061326  257261 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-07 17:30:47.081622: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexperiment_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experiments\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrain_and_test\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_and_test\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mload_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_data, create_dataset\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_model\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/src/train_and_test.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mload_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_file_paths, get_dataset_from_paths\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/tensorflow/__init__.py:467\u001b[0m\n\u001b[1;32m    465\u001b[0m     importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_keras.src.optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.src.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m    469\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DTypePolicy\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FloatDTypePolicy\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Function\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/api/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/api/activations/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/src/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/src/activations/__init__.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m threshold\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m object_registration\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n\u001b[1;32m     36\u001b[0m ALL_OBJECTS \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     37\u001b[0m     relu,\n\u001b[1;32m     38\u001b[0m     leaky_relu,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     sparsemax,\n\u001b[1;32m     66\u001b[0m }\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/src/saving/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_registered_object\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_keras_serializable\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/src/saving/saving_api.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mabsl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m legacy_h5_format\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m file_utils\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m json_utils\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m saving_options\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m saving_utils\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m object_registration\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io_utils\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mabsl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m losses\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/src/layers/__init__.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madditive_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdditiveAttention\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Attention\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouped_query_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     GroupedQueryAttention,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulti_head_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiHeadAttention\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvolutional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv1d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv1D\n",
      "File \u001b[0;32m/workspace/mai-object-recognition/practicals/p1/.venv/lib/python3.11/site-packages/keras/src/layers/attention/grouped_query_attention.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_flash_attention_enabled\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msoftmax\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Softmax\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meinsum_dense\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EinsumDense\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregularization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdropout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dropout\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1080\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1504\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1476\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1612\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importing from .py files\n",
    "\n",
    "from config import *\n",
    "from experiment_config import experiments\n",
    "from train_and_test import train_and_test\n",
    "from load_data import load_data, create_dataset\n",
    "from models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741389566.814773    2172 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22455 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_list = load_data(TRAIN_TXT)\n",
    "test_list = load_data(TEST_TXT)\n",
    "\n",
    "# Create dictionaries to store datasets for different batch sizes\n",
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "\n",
    "start_time = time.time()\n",
    "# Iterate over batch sizes and create datasets\n",
    "for batch_size in BATCH_SIZES:\n",
    "    train_datasets[batch_size] = create_dataset(\n",
    "        train_list, batch_size, is_training=True\n",
    "    )\n",
    "    test_datasets[batch_size] = create_dataset(test_list, batch_size, is_training=False)\n",
    "print(f\"Time taken to create datasets: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ej9VbIk_Sfj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model: resnet50 no-pretraining no-warmup\n",
      "In training loop: resnet50 no-pretraining no-warmup\n",
      "Recompiling model at epoch 0 (Optimizer changed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741389596.130585    2172 service.cc:148] XLA service 0x16dcf2b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741389596.130751    2172 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-03-07 23:19:56.939286: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741389600.328814    2172 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-07 23:20:08.091401: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6302_0', 112 bytes spill stores, 224 bytes spill loads\n",
      "\n",
      "2025-03-07 23:20:10.588146: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11157', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-03-07 23:20:10.803674: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6302', 192 bytes spill stores, 512 bytes spill loads\n",
      "\n",
      "2025-03-07 23:20:11.935847: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6785', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-03-07 23:20:12.113301: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6309', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "2025-03-07 23:20:12.248484: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11157', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2025-03-07 23:20:12.402351: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11157', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "I0000 00:00:1741389634.390715    2172 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training one epoch: 112.77s\n",
      "Epoch 0 training loss: 0.17, acc: 0.89, f1: 0.56, mAP: 0.74\n",
      "Time taken for testing one epoch: 46.13s\n",
      "Epoch 0 test loss: 0.26, acc: 0.74, f1: 0.04, mAP: 0.41\n",
      "Time taken for training one epoch: 51.63s\n",
      "Epoch 1 training loss: 0.09, acc: 0.97, f1: 0.72, mAP: 0.87\n",
      "Time taken for testing one epoch: 36.58s\n",
      "Epoch 1 test loss: 0.21, acc: 0.87, f1: 0.41, mAP: 0.63\n",
      "Time taken for training one epoch: 52.76s\n",
      "Epoch 2 training loss: 0.07, acc: 0.98, f1: 0.81, mAP: 0.93\n",
      "Time taken for testing one epoch: 37.75s\n",
      "Epoch 2 test loss: 0.27, acc: 0.86, f1: 0.60, mAP: 0.73\n",
      "Time taken for training one epoch: 53.92s\n",
      "Epoch 3 training loss: 0.05, acc: 0.99, f1: 0.86, mAP: 0.96\n",
      "Time taken for testing one epoch: 38.22s\n",
      "Epoch 3 test loss: 0.17, acc: 0.91, f1: 0.65, mAP: 0.79\n",
      "Time taken for training one epoch: 52.90s\n",
      "Epoch 4 training loss: 0.04, acc: 0.99, f1: 0.89, mAP: 0.97\n",
      "Time taken for testing one epoch: 37.72s\n",
      "Epoch 4 test loss: 0.17, acc: 0.91, f1: 0.66, mAP: 0.80\n",
      "Time taken for training one epoch: 53.13s\n",
      "Epoch 5 training loss: 0.03, acc: 1.00, f1: 0.92, mAP: 0.98\n",
      "Time taken for testing one epoch: 38.39s\n",
      "Epoch 5 test loss: 0.25, acc: 0.86, f1: 0.62, mAP: 0.76\n",
      "Time taken for training one epoch: 53.39s\n",
      "Epoch 6 training loss: 0.03, acc: 1.00, f1: 0.93, mAP: 0.98\n",
      "Time taken for testing one epoch: 38.55s\n",
      "Epoch 6 test loss: 0.21, acc: 0.89, f1: 0.62, mAP: 0.77\n",
      "Time taken for training one epoch: 54.22s\n",
      "Epoch 7 training loss: 0.02, acc: 1.00, f1: 0.94, mAP: 0.99\n",
      "Time taken for testing one epoch: 38.81s\n",
      "Epoch 7 test loss: 0.29, acc: 0.85, f1: 0.52, mAP: 0.68\n",
      "Time taken for training one epoch: 54.67s\n",
      "Epoch 8 training loss: 0.02, acc: 1.00, f1: 0.95, mAP: 0.99\n",
      "Time taken for testing one epoch: 38.94s\n",
      "Epoch 8 test loss: 0.20, acc: 0.89, f1: 0.67, mAP: 0.80\n",
      "Time taken for training one epoch: 54.23s\n",
      "Epoch 9 training loss: 0.02, acc: 1.00, f1: 0.96, mAP: 0.99\n",
      "Time taken for testing one epoch: 38.92s\n",
      "Epoch 9 test loss: 0.20, acc: 0.90, f1: 0.66, mAP: 0.80\n",
      "Time taken for training one epoch: 52.56s\n",
      "Epoch 10 training loss: 0.01, acc: 1.00, f1: 0.97, mAP: 1.00\n",
      "Time taken for testing one epoch: 37.57s\n",
      "Epoch 10 test loss: 0.22, acc: 0.90, f1: 0.70, mAP: 0.82\n",
      "Time taken for training one epoch: 53.48s\n",
      "Epoch 11 training loss: 0.01, acc: 1.00, f1: 0.98, mAP: 1.00\n",
      "Time taken for testing one epoch: 39.78s\n",
      "Epoch 11 test loss: 0.27, acc: 0.87, f1: 0.66, mAP: 0.80\n",
      "Training (resnet50 no-pretraining no-warmup) finished in: 1167.34 seconds\n",
      "Results saved to /workspace/mai-object-recognition/practicals/p1/data/02_results/model-experiments.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_loss.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_acc.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_f1.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_map.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_subset_acc.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_loss.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_acc.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_f1.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_map.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_subset_acc.csv\n"
     ]
    }
   ],
   "source": [
    "# Run model experiments\n",
    "exp_name = \"model-experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "\n",
    "    # Create the model\n",
    "    base_model, model = create_model(exp, exp_name)\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model,\n",
    "        base_model,\n",
    "        exp_name,\n",
    "        exp,\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        train_list,\n",
    "        test_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best experiment of the 9 model experiments\n",
    "\n",
    "df = pd.read_csv(RESULTS_DIR / f\"model-experiments.csv\")\n",
    "best_id = df.loc[df[\"Test mAP\"].idxmax(), \"ID\"]\n",
    "\n",
    "best_model_experiment_config = next(\n",
    "    exp for exp in experiments[\"model-experiments\"] if exp.id == best_id\n",
    ")\n",
    "\n",
    "best_model_experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model: batch_size: 64, learning_rate: 0.001\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training loop: batch_size: 64, learning_rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741335488.804120 1486723 service.cc:148] XLA service 0x2a477e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741335488.804155 1486723 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2025-03-07 08:18:09.295413: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741335491.711692 1486723 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-07 08:18:14.921285: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6300_0', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2025-03-07 08:18:16.144058: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6300', 192 bytes spill stores, 512 bytes spill loads\n",
      "\n",
      "2025-03-07 08:18:16.843900: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6307', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "2025-03-07 08:18:17.470262: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6791', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-03-07 08:18:17.651007: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11163', 440 bytes spill stores, 440 bytes spill loads\n",
      "\n",
      "2025-03-07 08:18:17.877144: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11163', 496 bytes spill stores, 496 bytes spill loads\n",
      "\n",
      "I0000 00:00:1741335516.240618 1486723 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training one epoch: 84.77s\n",
      "Epoch 0 training loss: 0.17, acc: 0.89, f1: 0.57, mAP: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 08:19:21.545454: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1738_0', 112 bytes spill stores, 224 bytes spill loads\n",
      "\n",
      "2025-03-07 08:19:21.619983: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1738', 192 bytes spill stores, 512 bytes spill loads\n",
      "\n",
      "2025-03-07 08:19:21.768963: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1745', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for testing one epoch: 21.74s\n",
      "Epoch 0 test loss: 0.27, acc: 0.58, f1: 0.00, mAP: 0.20\n",
      "Time taken for training one epoch: 68.98s\n",
      "Epoch 1 training loss: 0.08, acc: 0.98, f1: 0.78, mAP: 0.91\n",
      "Time taken for testing one epoch: 18.13s\n",
      "Epoch 1 test loss: 0.25, acc: 0.82, f1: 0.12, mAP: 0.54\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 68.72s\n",
      "Epoch 2 training loss: 0.05, acc: 0.99, f1: 0.87, mAP: 0.96\n",
      "Time taken for testing one epoch: 18.50s\n",
      "Epoch 2 test loss: 0.30, acc: 0.82, f1: 0.35, mAP: 0.62\n",
      "Time taken for training one epoch: 68.95s\n",
      "Epoch 3 training loss: 0.04, acc: 0.99, f1: 0.90, mAP: 0.98\n",
      "Time taken for testing one epoch: 18.42s\n",
      "Epoch 3 test loss: 0.17, acc: 0.91, f1: 0.67, mAP: 0.81\n",
      "Time taken for training one epoch: 67.92s\n",
      "Epoch 4 training loss: 0.03, acc: 1.00, f1: 0.92, mAP: 0.98\n",
      "Time taken for testing one epoch: 18.50s\n",
      "Epoch 4 test loss: 0.25, acc: 0.86, f1: 0.56, mAP: 0.72\n",
      "Time taken for training one epoch: 69.07s\n",
      "Epoch 5 training loss: 0.02, acc: 1.00, f1: 0.94, mAP: 0.99\n",
      "Time taken for testing one epoch: 18.44s\n",
      "Epoch 5 test loss: 0.31, acc: 0.80, f1: 0.50, mAP: 0.68\n",
      "Time taken for training one epoch: 68.84s\n",
      "Epoch 6 training loss: 0.02, acc: 1.00, f1: 0.95, mAP: 0.99\n",
      "Time taken for testing one epoch: 18.40s\n",
      "Epoch 6 test loss: 0.17, acc: 0.91, f1: 0.70, mAP: 0.84\n",
      "Time taken for training one epoch: 68.28s\n",
      "Epoch 7 training loss: 0.01, acc: 1.00, f1: 0.96, mAP: 1.00\n",
      "Time taken for testing one epoch: 18.53s\n",
      "Epoch 7 test loss: 0.25, acc: 0.85, f1: 0.59, mAP: 0.74\n",
      "Time taken for training one epoch: 69.52s\n",
      "Epoch 8 training loss: 0.01, acc: 1.00, f1: 0.96, mAP: 0.99\n",
      "Time taken for testing one epoch: 18.50s\n",
      "Epoch 8 test loss: 0.22, acc: 0.90, f1: 0.71, mAP: 0.84\n",
      "Time taken for training one epoch: 68.32s\n",
      "Epoch 9 training loss: 0.01, acc: 1.00, f1: 0.97, mAP: 1.00\n",
      "Time taken for testing one epoch: 18.49s\n",
      "Epoch 9 test loss: 0.18, acc: 0.92, f1: 0.70, mAP: 0.84\n",
      "Time taken for training one epoch: 68.47s\n",
      "Epoch 10 training loss: 0.01, acc: 1.00, f1: 0.98, mAP: 1.00\n",
      "Time taken for testing one epoch: 19.75s\n",
      "Epoch 10 test loss: 0.21, acc: 0.89, f1: 0.70, mAP: 0.84\n",
      "Time taken for training one epoch: 68.34s\n",
      "Epoch 11 training loss: 0.01, acc: 1.00, f1: 0.99, mAP: 1.00\n",
      "Time taken for testing one epoch: 18.57s\n",
      "Epoch 11 test loss: 0.25, acc: 0.88, f1: 0.66, mAP: 0.80\n",
      "Training (batch_size: 64, learning_rate: 0.001) finished in: 1066.46 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-15-test_subset_acc.csv\n",
      "Current memory usage (bytes): 228603904\n",
      "Peak memory usage (bytes): 5666849536\n",
      "Defining model: batch_size: 64, learning_rate: 0.01\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 64, learning_rate: 0.01\n",
      "Time taken for training one epoch: 70.31s\n",
      "Epoch 0 training loss: 0.44, acc: 0.72, f1: 0.34, mAP: 0.52\n",
      "Time taken for testing one epoch: 18.83s\n",
      "Epoch 0 test loss: 0.21, acc: 0.76, f1: 0.00, mAP: 0.56\n",
      "Time taken for training one epoch: 69.17s\n",
      "Epoch 1 training loss: 0.20, acc: 0.77, f1: 0.43, mAP: 0.58\n",
      "Time taken for testing one epoch: 18.12s\n",
      "Epoch 1 test loss: 0.21, acc: 0.76, f1: 0.00, mAP: 0.56\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 70.60s\n",
      "Epoch 2 training loss: 0.19, acc: 0.79, f1: 0.42, mAP: 0.59\n",
      "Time taken for testing one epoch: 18.67s\n",
      "Epoch 2 test loss: 0.21, acc: 0.77, f1: 0.48, mAP: 0.56\n",
      "Time taken for training one epoch: 70.06s\n",
      "Epoch 3 training loss: 0.19, acc: 0.81, f1: 0.43, mAP: 0.60\n",
      "Time taken for testing one epoch: 18.54s\n",
      "Epoch 3 test loss: 0.20, acc: 0.82, f1: 0.35, mAP: 0.59\n",
      "Time taken for training one epoch: 68.04s\n",
      "Epoch 4 training loss: 0.19, acc: 0.82, f1: 0.44, mAP: 0.61\n",
      "Time taken for testing one epoch: 18.48s\n",
      "Epoch 4 test loss: 0.20, acc: 0.80, f1: 0.47, mAP: 0.58\n",
      "Time taken for training one epoch: 70.03s\n",
      "Epoch 5 training loss: 0.19, acc: 0.83, f1: 0.45, mAP: 0.61\n",
      "Time taken for testing one epoch: 18.23s\n",
      "Epoch 5 test loss: 0.19, acc: 0.84, f1: 0.42, mAP: 0.60\n",
      "Time taken for training one epoch: 68.89s\n",
      "Epoch 6 training loss: 0.19, acc: 0.84, f1: 0.45, mAP: 0.62\n",
      "Time taken for testing one epoch: 17.80s\n",
      "Epoch 6 test loss: 0.20, acc: 0.83, f1: 0.41, mAP: 0.60\n",
      "Time taken for training one epoch: 68.44s\n",
      "Epoch 7 training loss: 0.18, acc: 0.84, f1: 0.44, mAP: 0.63\n",
      "Time taken for testing one epoch: 18.59s\n",
      "Epoch 7 test loss: 0.20, acc: 0.83, f1: 0.27, mAP: 0.59\n",
      "Time taken for training one epoch: 68.94s\n",
      "Epoch 8 training loss: 0.18, acc: 0.85, f1: 0.44, mAP: 0.63\n",
      "Time taken for testing one epoch: 18.16s\n",
      "Epoch 8 test loss: 0.19, acc: 0.85, f1: 0.30, mAP: 0.61\n",
      "Time taken for training one epoch: 70.29s\n",
      "Epoch 9 training loss: 0.18, acc: 0.86, f1: 0.44, mAP: 0.64\n",
      "Time taken for testing one epoch: 18.32s\n",
      "Epoch 9 test loss: 0.19, acc: 0.85, f1: 0.35, mAP: 0.61\n",
      "Time taken for training one epoch: 68.59s\n",
      "Epoch 10 training loss: 0.17, acc: 0.87, f1: 0.44, mAP: 0.64\n",
      "Time taken for testing one epoch: 18.72s\n",
      "Epoch 10 test loss: 0.44, acc: 0.64, f1: 0.09, mAP: 0.34\n",
      "Time taken for training one epoch: 68.57s\n",
      "Epoch 11 training loss: 0.17, acc: 0.88, f1: 0.45, mAP: 0.66\n",
      "Time taken for testing one epoch: 18.14s\n",
      "Epoch 11 test loss: 0.19, acc: 0.86, f1: 0.43, mAP: 0.63\n",
      "Training (batch_size: 64, learning_rate: 0.01) finished in: 1052.88 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-16-test_subset_acc.csv\n",
      "Current memory usage (bytes): 456824576\n",
      "Peak memory usage (bytes): 5919230720\n",
      "Defining model: batch_size: 64, learning_rate: 0.1\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 64, learning_rate: 0.1\n",
      "Time taken for training one epoch: 71.00s\n",
      "Epoch 0 training loss: 5.17, acc: 0.72, f1: 0.38, mAP: 0.54\n",
      "Time taken for testing one epoch: 18.67s\n",
      "Epoch 0 test loss: 3.51, acc: 0.65, f1: 0.03, mAP: 0.48\n",
      "Time taken for training one epoch: 67.76s\n",
      "Epoch 1 training loss: 0.20, acc: 0.76, f1: 0.42, mAP: 0.58\n",
      "Time taken for testing one epoch: 18.02s\n",
      "Epoch 1 test loss: 0.20, acc: 0.78, f1: 0.41, mAP: 0.57\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 67.93s\n",
      "Epoch 2 training loss: 0.20, acc: 0.77, f1: 0.43, mAP: 0.58\n",
      "Time taken for testing one epoch: 18.68s\n",
      "Epoch 2 test loss: 0.20, acc: 0.78, f1: 0.44, mAP: 0.57\n",
      "Time taken for training one epoch: 68.03s\n",
      "Epoch 3 training loss: 0.20, acc: 0.77, f1: 0.43, mAP: 0.58\n",
      "Time taken for testing one epoch: 18.68s\n",
      "Epoch 3 test loss: 0.21, acc: 0.78, f1: 0.37, mAP: 0.57\n",
      "Time taken for training one epoch: 70.68s\n",
      "Epoch 4 training loss: 0.20, acc: 0.77, f1: 0.43, mAP: 0.58\n",
      "Time taken for testing one epoch: 18.66s\n",
      "Epoch 4 test loss: 0.20, acc: 0.79, f1: 0.39, mAP: 0.57\n",
      "Time taken for training one epoch: 68.15s\n",
      "Epoch 5 training loss: 0.20, acc: 0.77, f1: 0.43, mAP: 0.58\n",
      "Time taken for testing one epoch: 18.21s\n",
      "Epoch 5 test loss: 0.20, acc: 0.79, f1: 0.43, mAP: 0.57\n",
      "Time taken for training one epoch: 68.01s\n",
      "Epoch 6 training loss: 0.20, acc: 0.78, f1: 0.42, mAP: 0.59\n",
      "Time taken for testing one epoch: 18.48s\n",
      "Epoch 6 test loss: 0.20, acc: 0.80, f1: 0.34, mAP: 0.58\n",
      "Time taken for training one epoch: 67.87s\n",
      "Epoch 7 training loss: 0.20, acc: 0.78, f1: 0.41, mAP: 0.59\n",
      "Time taken for testing one epoch: 18.67s\n",
      "Epoch 7 test loss: 0.20, acc: 0.79, f1: 0.26, mAP: 0.57\n",
      "Time taken for training one epoch: 68.13s\n",
      "Epoch 8 training loss: 0.20, acc: 0.79, f1: 0.42, mAP: 0.59\n",
      "Time taken for testing one epoch: 18.60s\n",
      "Epoch 8 test loss: 0.20, acc: 0.80, f1: 0.39, mAP: 0.58\n",
      "Time taken for training one epoch: 68.08s\n",
      "Epoch 9 training loss: 0.20, acc: 0.79, f1: 0.41, mAP: 0.59\n",
      "Time taken for testing one epoch: 18.55s\n",
      "Epoch 9 test loss: 0.20, acc: 0.79, f1: 0.47, mAP: 0.57\n",
      "Time taken for training one epoch: 70.94s\n",
      "Epoch 10 training loss: 0.19, acc: 0.79, f1: 0.41, mAP: 0.59\n",
      "Time taken for testing one epoch: 18.22s\n",
      "Epoch 10 test loss: 0.20, acc: 0.81, f1: 0.32, mAP: 0.58\n",
      "Time taken for training one epoch: 67.60s\n",
      "Epoch 11 training loss: 0.19, acc: 0.80, f1: 0.41, mAP: 0.59\n",
      "Time taken for testing one epoch: 18.07s\n",
      "Epoch 11 test loss: 0.20, acc: 0.80, f1: 0.40, mAP: 0.58\n",
      "Training (batch_size: 64, learning_rate: 0.1) finished in: 1046.05 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-17-test_subset_acc.csv\n",
      "Current memory usage (bytes): 687323136\n",
      "Peak memory usage (bytes): 6153138688\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter experiments\n",
    "\n",
    "exp_name = \"hyperparameter-experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "\n",
    "    # Create the model\n",
    "    base_model, model = create_model(exp, exp_name, best_model_experiment_config)\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model,\n",
    "        base_model,\n",
    "        exp_name,\n",
    "        exp,\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        train_list,\n",
    "        test_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentConfig(id=15, title='batch_size: 64, learning_rate: 0.001', net_name=['resnet50', 'ResNet50'], train_from_scratch=False, warm_up=True, batch_size=64, n_epochs=12, last_layer_activation='sigmoid', learning_rate=0.001, loss='binary_crossentropy', classifier_head='default')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the best experiment of the 9 hyperparameter experiments\n",
    "\n",
    "df = pd.read_csv(RESULTS_DIR / f\"hyperparameter-experiments.csv\")\n",
    "best_id = df.loc[df[\"Test mAP\"].idxmax(), \"ID\"]\n",
    "\n",
    "best_hyperparameter_experiment_config = next(\n",
    "    exp for exp in experiments[\"hyperparameter-experiments\"] if exp.id == best_id\n",
    ")\n",
    "\n",
    "best_hyperparameter_experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run augmentation experiments\n",
    "\n",
    "exp_name = \"augmentation-experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "\n",
    "    # Create the model\n",
    "    base_model, model = create_model(\n",
    "        exp, exp_name, best_hyperparameter_experiment_config\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model,\n",
    "        exp_name,\n",
    "        exp,\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        train_list,\n",
    "        test_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model: classifier_head: attention\n",
      "Reusing from best hyperparameter experiment:\n",
      "\tnet_name: ['resnet50', 'ResNet50'],\n",
      "\ttrain_from_scratch: False,\n",
      "\twarm_up: True,\n",
      "\tbatch_size: 64,\n",
      "\tlearning_rate: 0.001,\n",
      "\tloss: binary_crossentropy,\n",
      "\tlast_layer_activation: sigmoid\n",
      "In training loop: classifier_head: attention\n",
      "Freezing base model layers for warmup.\n",
      "Recompiling model at epoch 0 (Optimizer changed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741364154.375972  177183 service.cc:148] XLA service 0xfca9af0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741364154.376114  177183 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-03-07 16:15:54.725472: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741364156.612851  177183 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-07 16:16:05.989336: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6880', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-03-07 16:16:06.177585: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3157', 216 bytes spill stores, 620 bytes spill loads\n",
      "\n",
      "2025-03-07 16:16:07.496858: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_49_0', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1741364177.382172  177183 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training one epoch: 69.78s\n",
      "Epoch 0 training loss: 0.26, acc: 0.74, f1: 0.38, mAP: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 16:17:04.877941: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1758_0', 112 bytes spill stores, 224 bytes spill loads\n",
      "\n",
      "2025-03-07 16:17:06.722508: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1758', 192 bytes spill stores, 512 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for testing one epoch: 45.69s\n",
      "Epoch 0 test loss: 0.18, acc: 0.86, f1: 0.31, mAP: 0.65\n",
      "Time taken for training one epoch: 36.24s\n",
      "Epoch 1 training loss: 0.17, acc: 0.86, f1: 0.45, mAP: 0.67\n",
      "Time taken for testing one epoch: 27.31s\n",
      "Epoch 1 test loss: 0.17, acc: 0.88, f1: 0.37, mAP: 0.67\n",
      "Time taken for training one epoch: 35.14s\n",
      "Epoch 2 training loss: 0.16, acc: 0.88, f1: 0.48, mAP: 0.70\n",
      "Time taken for testing one epoch: 26.71s\n",
      "Epoch 2 test loss: 0.17, acc: 0.89, f1: 0.39, mAP: 0.68\n",
      "Unfreezing base model at epoch 3\n",
      "Recompiling model at epoch 3 (Optimizer changed)\n",
      "Time taken for training one epoch: 116.15s\n",
      "Epoch 3 training loss: 0.15, acc: 0.91, f1: 0.60, mAP: 0.76\n",
      "Time taken for testing one epoch: 36.76s\n",
      "Epoch 3 test loss: 0.34, acc: 0.61, f1: 0.00, mAP: 0.25\n",
      "Time taken for training one epoch: 47.18s\n",
      "Epoch 4 training loss: 0.09, acc: 0.97, f1: 0.74, mAP: 0.87\n",
      "Time taken for testing one epoch: 27.36s\n",
      "Epoch 4 test loss: 0.29, acc: 0.79, f1: 0.14, mAP: 0.48\n",
      "Time taken for training one epoch: 50.17s\n",
      "Epoch 5 training loss: 0.06, acc: 0.98, f1: 0.80, mAP: 0.92\n",
      "Time taken for testing one epoch: 27.44s\n",
      "Epoch 5 test loss: 0.22, acc: 0.88, f1: 0.47, mAP: 0.65\n",
      "Time taken for training one epoch: 49.28s\n",
      "Epoch 6 training loss: 0.05, acc: 0.99, f1: 0.85, mAP: 0.95\n",
      "Time taken for testing one epoch: 26.97s\n",
      "Epoch 6 test loss: 0.21, acc: 0.86, f1: 0.51, mAP: 0.68\n",
      "Time taken for training one epoch: 50.39s\n",
      "Epoch 7 training loss: 0.04, acc: 0.99, f1: 0.88, mAP: 0.96\n",
      "Time taken for testing one epoch: 26.60s\n",
      "Epoch 7 test loss: 0.26, acc: 0.84, f1: 0.49, mAP: 0.68\n",
      "Time taken for training one epoch: 49.81s\n",
      "Epoch 8 training loss: 0.03, acc: 0.99, f1: 0.90, mAP: 0.97\n",
      "Time taken for testing one epoch: 27.51s\n",
      "Epoch 8 test loss: 0.20, acc: 0.88, f1: 0.63, mAP: 0.76\n",
      "Time taken for training one epoch: 52.12s\n",
      "Epoch 9 training loss: 0.02, acc: 1.00, f1: 0.94, mAP: 0.99\n",
      "Time taken for testing one epoch: 28.68s\n",
      "Epoch 9 test loss: 0.19, acc: 0.90, f1: 0.66, mAP: 0.79\n",
      "Time taken for training one epoch: 50.31s\n",
      "Epoch 10 training loss: 0.02, acc: 1.00, f1: 0.94, mAP: 0.98\n",
      "Time taken for testing one epoch: 25.60s\n",
      "Epoch 10 test loss: 0.22, acc: 0.87, f1: 0.62, mAP: 0.76\n",
      "Time taken for training one epoch: 51.31s\n",
      "Epoch 11 training loss: 0.02, acc: 1.00, f1: 0.95, mAP: 0.99\n",
      "Time taken for testing one epoch: 27.64s\n",
      "Epoch 11 test loss: 0.20, acc: 0.90, f1: 0.70, mAP: 0.82\n",
      "Training (classifier_head: attention) finished in: 1012.39 seconds\n",
      "Results saved to /workspace/mai-object-recognition/practicals/p1/data/02_results/classfier_head-experiments.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-train_loss.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-train_acc.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-train_f1.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-train_map.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-train_subset_acc.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-test_loss.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-test_acc.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-test_f1.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-test_map.csv\n",
      "History saved to /workspace/mai-object-recognition/practicals/p1/data/01_histories/resnet50-19-test_subset_acc.csv\n",
      "Current memory usage (bytes): 229232384\n",
      "Peak memory usage (bytes): 5679862016\n"
     ]
    }
   ],
   "source": [
    "# Run classifier head experiments\n",
    "\n",
    "exp_name = \"classfier_head-experiments\"\n",
    "for exp in experiments[exp_name][1:]:\n",
    "\n",
    "    # Create the model\n",
    "    base_model, model = create_model(\n",
    "        exp, exp_name, best_hyperparameter_experiment_config\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model,\n",
    "        base_model,\n",
    "        exp_name,\n",
    "        exp,\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        train_list,\n",
    "        test_list,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
