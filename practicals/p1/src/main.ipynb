{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDqDj4kC9sFJ"
   },
   "source": [
    "# Master course in Object Recognition\n",
    "## Practice 1\n",
    "\n",
    "### Title: Deep learning advanced architectures\n",
    "\n",
    "The goal is to practice advanced deep learning architectures for multi-label classification in [Pascal VOC dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html). We specifically check ResNet50, Inception and MobileNet. We will see 1) how pretrained ResNet50 on imagenet performs on multi-label images, 2) how to modify classification head and 3) implementation of F1 metric.\n",
    "\n",
    "### NOTES\n",
    "\n",
    "- Hyperparameters are modifiable,\n",
    "- The dataset is PASCAL VOC 2012,\n",
    "- The code uses the KERAS library,\n",
    "- The code can run in google colab.\n",
    "- How to finetune on a pretrained model not included (i.e. freeze the pretrained network and train the head, then finetune everything),\n",
    "- No validation set has been defined. The test and validation sets are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "import tensorflow.keras.applications as app\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing from .py files\n",
    "\n",
    "from metrics import f1_metric, mean_average_precision\n",
    "from config import *\n",
    "from experiment_config import experiments\n",
    "from train_and_test import train_and_test\n",
    "from load_data import load_data, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create datasets: 0.9064459800720215 seconds\n"
     ]
    }
   ],
   "source": [
    "train_list = load_data(TRAIN_TXT)\n",
    "test_list = load_data(TEST_TXT)\n",
    "\n",
    "# Create dictionaries to store datasets for different batch sizes\n",
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "\n",
    "start_time = time.time()\n",
    "# Iterate over batch sizes and create datasets\n",
    "for batch_size in BATCH_SIZES:\n",
    "    train_datasets[batch_size] = create_dataset(\n",
    "        train_list, batch_size, is_training=True\n",
    "    )\n",
    "    test_datasets[batch_size] = create_dataset(test_list, batch_size, is_training=False)\n",
    "print(f\"Time taken to create datasets: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8ej9VbIk_Sfj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model: resnet50 no-pretraining no-warmup\n",
      "In training loop: resnet50 no-pretraining no-warmup\n",
      "Time taken for training one epoch: 42.08s\n",
      "Epoch 0 training loss: 0.47, acc: 0.63, f1: 0.27, mAP: 0.45\n",
      "Time taken for testing one epoch: 7.38s\n",
      "Epoch 0 test loss: 0.49, acc: 0.71, f1: 0.45, mAP: 0.53\n",
      "Time taken for training one epoch: 31.07s\n",
      "Epoch 1 training loss: 0.19, acc: 0.86, f1: 0.46, mAP: 0.71\n",
      "Time taken for testing one epoch: 6.27s\n",
      "Epoch 1 test loss: 0.33, acc: 0.63, f1: 0.01, mAP: 0.24\n",
      "Time taken for training one epoch: 31.52s\n",
      "Epoch 2 training loss: 0.12, acc: 0.94, f1: 0.59, mAP: 0.79\n",
      "Time taken for testing one epoch: 6.12s\n",
      "Epoch 2 test loss: 0.55, acc: 0.46, f1: 0.02, mAP: 0.16\n",
      "Training (resnet50 no-pretraining no-warmup) finished in: 124.46 seconds\n",
      "Results saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/02_results/model-experiments.csv\n",
      "Model saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/models/resnet50-0.weights.h5\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_loss.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_acc.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_f1.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-train_map.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_loss.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_acc.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_f1.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-0-test_map.csv\n"
     ]
    }
   ],
   "source": [
    "# Run model experiments\n",
    "exp_name = \"model-experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "    print(f\"Defining model: {exp.title}\")\n",
    "\n",
    "    # Select the corresponding network class\n",
    "    mynet = getattr(getattr(app, exp.net_name[0]), exp.net_name[1])\n",
    "\n",
    "    # Create the base pre-trained model\n",
    "    base_model = (\n",
    "        mynet(include_top=False)\n",
    "        if exp.train_from_scratch\n",
    "        else mynet(weights=\"imagenet\", include_top=False)\n",
    "    )\n",
    "\n",
    "    # Apply warm-up strategy\n",
    "    base_model.trainable = not exp.warm_up\n",
    "\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "    predictions = Dense(num_classes, activation=exp.last_layer_activation)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Define optimizers\n",
    "    warmup_optimizer = optimizers.RMSprop(learning_rate=exp.learning_rate * 0.1)\n",
    "    opt_rms = optimizers.RMSprop(learning_rate=exp.learning_rate)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        loss=exp.loss,\n",
    "        optimizer=warmup_optimizer if exp.warm_up else opt_rms,\n",
    "        metrics=[\"AUC\", f1_metric, mean_average_precision],\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model, exp_name, exp, train_dataset, test_dataset, train_list, test_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentConfig(id=0, title='resnet50 no-pretraining no-warmup', net_name=['resnet50', 'ResNet50'], train_from_scratch=True, warm_up=False, batch_size=32, n_epochs=3, last_layer_activation='sigmoid', learning_rate=0.001, loss='binary_crossentropy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the best experiment of the 9 model experiments\n",
    "\n",
    "df = pd.read_csv(RESULTS_DIR / f\"model-experiments.csv\")\n",
    "best_id = df.loc[df[\"Test mAP\"].idxmax(), \"ID\"]\n",
    "\n",
    "best_model_experiment_config = next(\n",
    "    exp for exp in experiments[\"model-experiments\"] if exp.id == best_id\n",
    ")\n",
    "\n",
    "best_model_experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model: batch_size: 16, learning_rate: 0.001\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: True, warm_up: False from best model experiment\n",
      "In training loop: batch_size: 16, learning_rate: 0.001\n",
      "Time taken for training one epoch: 24.91s\n",
      "Epoch 0 training loss: 0.52, acc: 0.59, f1: 0.23, mAP: 0.38\n",
      "Time taken for testing one epoch: 5.01s\n",
      "Epoch 0 test loss: 0.42, acc: 0.63, f1: 0.29, mAP: 0.47\n",
      "Time taken for training one epoch: 17.22s\n",
      "Epoch 1 training loss: 0.25, acc: 0.77, f1: 0.34, mAP: 0.55\n",
      "Time taken for testing one epoch: 3.65s\n",
      "Epoch 1 test loss: 0.34, acc: 0.62, f1: 0.00, mAP: 0.25\n",
      "Time taken for training one epoch: 15.54s\n",
      "Epoch 2 training loss: 0.16, acc: 0.91, f1: 0.49, mAP: 0.73\n",
      "Time taken for testing one epoch: 3.82s\n",
      "Epoch 2 test loss: 0.32, acc: 0.65, f1: 0.07, mAP: 0.33\n",
      "Training (batch_size: 16, learning_rate: 0.001) finished in: 70.16 seconds\n",
      "Results saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/02_results/model-experiments.csv\n",
      "Model saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/models/resnet50-9.weights.h5\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_loss.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_acc.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_f1.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_map.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_loss.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_acc.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_f1.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_map.csv\n",
      "Defining model: batch_size: 16, learning_rate: 0.01\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: True, warm_up: False from best model experiment\n",
      "In training loop: batch_size: 16, learning_rate: 0.01\n",
      "Time taken for training one epoch: 24.49s\n",
      "Epoch 0 training loss: 1.99, acc: 0.64, f1: 0.26, mAP: 0.43\n",
      "Time taken for testing one epoch: 4.66s\n",
      "Epoch 0 test loss: 187843135738688320.00, acc: 0.64, f1: 0.38, mAP: 0.45\n",
      "Time taken for training one epoch: 15.25s\n",
      "Epoch 1 training loss: 36798261884878848.00, acc: 0.66, f1: 0.32, mAP: 0.49\n",
      "Time taken for testing one epoch: 3.54s\n",
      "Epoch 1 test loss: 817870071398.40, acc: 0.64, f1: 0.38, mAP: 0.45\n",
      "Time taken for training one epoch: 15.66s\n",
      "Epoch 2 training loss: 178565398528.00, acc: 0.68, f1: 0.32, mAP: 0.51\n",
      "Time taken for testing one epoch: 3.58s\n",
      "Epoch 2 test loss: 720352140.80, acc: 0.64, f1: 0.38, mAP: 0.45\n",
      "Training (batch_size: 16, learning_rate: 0.01) finished in: 67.18 seconds\n",
      "Results saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/02_results/model-experiments.csv\n",
      "Model saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/models/resnet50-10.weights.h5\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_loss.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_acc.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_f1.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_map.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_loss.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_acc.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_f1.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_map.csv\n",
      "Defining model: batch_size: 16, learning_rate: 0.1\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: True, warm_up: False from best model experiment\n",
      "In training loop: batch_size: 16, learning_rate: 0.1\n",
      "Time taken for training one epoch: 24.21s\n",
      "Epoch 0 training loss: 103.62, acc: 0.58, f1: 0.17, mAP: 0.33\n",
      "Time taken for testing one epoch: 4.44s\n",
      "Epoch 0 test loss: 1081484021053235920896.00, acc: 0.50, f1: 0.00, mAP: 0.17\n",
      "Time taken for training one epoch: 18.64s\n",
      "Epoch 1 training loss: 194504715261295198208.00, acc: 0.63, f1: 0.20, mAP: 0.46\n",
      "Time taken for testing one epoch: 3.69s\n",
      "Epoch 1 test loss: 4098411043225.60, acc: 0.50, f1: 0.00, mAP: 0.17\n",
      "Time taken for training one epoch: 14.60s\n",
      "Epoch 2 training loss: 833205501952.00, acc: 0.65, f1: 0.27, mAP: 0.48\n",
      "Time taken for testing one epoch: 3.67s\n",
      "Epoch 2 test loss: 481258976.00, acc: 0.50, f1: 0.00, mAP: 0.17\n",
      "Training (batch_size: 16, learning_rate: 0.1) finished in: 69.25 seconds\n",
      "Results saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/02_results/model-experiments.csv\n",
      "Model saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/models/resnet50-11.weights.h5\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_loss.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_acc.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_f1.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_map.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_loss.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_acc.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_f1.csv\n",
      "History saved to /Users/sheena/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_map.csv\n",
      "Defining model: batch_size: 32, learning_rate: 0.001\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: True, warm_up: False from best model experiment\n",
      "In training loop: batch_size: 32, learning_rate: 0.001\n",
      "Time taken for training one epoch: 40.87s\n",
      "Epoch 0 training loss: 0.48, acc: 0.67, f1: 0.29, mAP: 0.48\n",
      "Time taken for testing one epoch: 8.46s\n",
      "Epoch 0 test loss: 0.36, acc: 0.62, f1: 0.00, mAP: 0.22\n",
      "Time taken for training one epoch: 32.34s\n",
      "Epoch 1 training loss: 0.19, acc: 0.82, f1: 0.40, mAP: 0.64\n",
      "Time taken for testing one epoch: 6.15s\n",
      "Epoch 1 test loss: 0.27, acc: 0.64, f1: 0.00, mAP: 0.24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_datasets[exp\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m     47\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_datasets[exp\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m---> 49\u001b[0m \u001b[43mtrain_and_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_list\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/src/train_and_test.py:182\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, exp_name, exp, train_dataset, test_dataset, train_list, test_list)\u001b[0m\n\u001b[1;32m    179\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(train_list)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Train one epoch\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m train_loss, train_acc, train_f1, train_map \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_train_steps\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m train_loss_history\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m    186\u001b[0m train_acc_history\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/practicals/p1/src/train_and_test.py:18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataset, n_train_steps)\u001b[0m\n\u001b[1;32m     16\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m islice(train_dataset, n_train_steps):\n\u001b[0;32m---> 18\u001b[0m     loss, acc, f1, map_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     20\u001b[0m     train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:601\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata\u001b[39m():\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[0;32m--> 601\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:227\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[1;32m    226\u001b[0m     ):\n\u001b[0;32m--> 227\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Development/master-dev/semester-2/mai-object-recognition/venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run hyperparameter experiments\n",
    "\n",
    "exp_name = \"hyperparameter-experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "    print(f\"Defining model: {exp.title}\")\n",
    "    print(\n",
    "        f\"Reusing net_name: {best_model_experiment_config.net_name}, train_from_scratch: {best_model_experiment_config.train_from_scratch}, warm_up: {best_model_experiment_config.warm_up} from best model experiment\"\n",
    "    )\n",
    "    exp.net_name = best_model_experiment_config.net_name\n",
    "    exp.train_from_scratch = best_model_experiment_config.train_from_scratch\n",
    "    exp.warm_up = best_model_experiment_config.warm_up\n",
    "\n",
    "    # Select the corresponding network class\n",
    "    mynet = getattr(getattr(app, exp.net_name[0]), exp.net_name[1])\n",
    "\n",
    "    # Create the base pre-trained model\n",
    "    base_model = (\n",
    "        mynet(include_top=False)\n",
    "        if exp.train_from_scratch\n",
    "        else mynet(weights=\"imagenet\", include_top=False)\n",
    "    )\n",
    "\n",
    "    # Apply warm-up strategy\n",
    "    base_model.trainable = not exp.warm_up\n",
    "\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "    predictions = Dense(num_classes, activation=exp.last_layer_activation)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Define optimizers\n",
    "    warmup_optimizer = optimizers.RMSprop(learning_rate=exp.learning_rate * 0.1)\n",
    "    opt_rms = optimizers.RMSprop(learning_rate=exp.learning_rate)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        loss=exp.loss,\n",
    "        optimizer=warmup_optimizer if exp.warm_up else opt_rms,\n",
    "        metrics=[\"AUC\", f1_metric, mean_average_precision],\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model, exp_name, exp, train_dataset, test_dataset, train_list, test_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best experiment of the 9 hyperparameter experiments\n",
    "\n",
    "df = pd.read_csv(RESULTS_DIR / f\"hyperparameter-experiments.csv\")\n",
    "best_id = df.loc[df[\"Test mAP\"].idxmax(), \"ID\"]\n",
    "\n",
    "best_hyperparameter_experiment_config = next(\n",
    "    exp for exp in experiments[\"hyperparameter-experiments\"] if exp.id == best_id\n",
    ")\n",
    "\n",
    "best_hyperparameter_experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run augmentation experiments\n",
    "\n",
    "exp_name = \"augmentation-experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "    print(f\"Defining model: {exp.title}\")\n",
    "    print(\n",
    "        f\"Reusing net_name: {best_hyperparameter_experiment_config.net_name}, train_from_scratch: {best_hyperparameter_experiment_config.train_from_scratch}, warm_up: {best_hyperparameter_experiment_config.warm_up} from best hyperparameter experiment\"\n",
    "    )\n",
    "    exp.net_name = best_hyperparameter_experiment_config.net_name\n",
    "    exp.train_from_scratch = best_hyperparameter_experiment_config.train_from_scratch\n",
    "    exp.warm_up = best_hyperparameter_experiment_config.warm_up\n",
    "    exp.batch_size = best_hyperparameter_experiment_config.batch_size\n",
    "    exp.learning_rate = best_hyperparameter_experiment_config.learning_rate\n",
    "    exp.loss = best_hyperparameter_experiment_config.loss\n",
    "    exp.last_layer_activation = (\n",
    "        best_hyperparameter_experiment_config.last_layer_activation\n",
    "    )\n",
    "\n",
    "    # Select the corresponding network class\n",
    "    mynet = getattr(getattr(app, exp.net_name[0]), exp.net_name[1])\n",
    "\n",
    "    # Create the base pre-trained model\n",
    "    base_model = (\n",
    "        mynet(include_top=False)\n",
    "        if exp.train_from_scratch\n",
    "        else mynet(weights=\"imagenet\", include_top=False)\n",
    "    )\n",
    "\n",
    "    # Apply warm-up strategy\n",
    "    base_model.trainable = not exp.warm_up\n",
    "\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "    predictions = Dense(num_classes, activation=exp.last_layer_activation)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Define optimizers\n",
    "    warmup_optimizer = optimizers.RMSprop(learning_rate=exp.learning_rate * 0.1)\n",
    "    opt_rms = optimizers.RMSprop(learning_rate=exp.learning_rate)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        loss=exp.loss,\n",
    "        optimizer=warmup_optimizer if exp.warm_up else opt_rms,\n",
    "        metrics=[\"AUC\", f1_metric, mean_average_precision],\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model, exp_name, exp, train_dataset, test_dataset, train_list, test_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier head experiments\n",
    "\n",
    "exp_name = \"classfier_head_experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "    print(f\"Defining model: {exp.title}\")\n",
    "    print(\n",
    "        f\"Reusing net_name: {best_hyperparameter_experiment_config.net_name}, train_from_scratch: {best_hyperparameter_experiment_config.train_from_scratch}, warm_up: {best_hyperparameter_experiment_config.warm_up} from best hyperparameter experiment\"\n",
    "    )\n",
    "    exp.net_name = best_hyperparameter_experiment_config.net_name\n",
    "    exp.train_from_scratch = best_hyperparameter_experiment_config.train_from_scratch\n",
    "    exp.warm_up = best_hyperparameter_experiment_config.warm_up\n",
    "    exp.batch_size = best_hyperparameter_experiment_config.batch_size\n",
    "    exp.learning_rate = best_hyperparameter_experiment_config.learning_rate\n",
    "    exp.loss = best_hyperparameter_experiment_config.loss\n",
    "    exp.last_layer_activation = (\n",
    "        best_hyperparameter_experiment_config.last_layer_activation\n",
    "    )\n",
    "\n",
    "    # Select the corresponding network class\n",
    "    mynet = getattr(getattr(app, exp.net_name[0]), exp.net_name[1])\n",
    "\n",
    "    # Create the base pre-trained model\n",
    "    base_model = (\n",
    "        mynet(include_top=False)\n",
    "        if exp.train_from_scratch\n",
    "        else mynet(weights=\"imagenet\", include_top=False)\n",
    "    )\n",
    "\n",
    "    # Apply warm-up strategy\n",
    "    base_model.trainable = not exp.warm_up\n",
    "\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "    predictions = Dense(num_classes, activation=exp.last_layer_activation)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Define optimizers\n",
    "    warmup_optimizer = optimizers.RMSprop(learning_rate=exp.learning_rate * 0.1)\n",
    "    opt_rms = optimizers.RMSprop(learning_rate=exp.learning_rate)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        loss=exp.loss,\n",
    "        optimizer=warmup_optimizer if exp.warm_up else opt_rms,\n",
    "        metrics=[\"AUC\", f1_metric, mean_average_precision],\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model, exp_name, exp, train_dataset, test_dataset, train_list, test_list\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
