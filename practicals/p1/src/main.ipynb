{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDqDj4kC9sFJ"
   },
   "source": [
    "# Master course in Object Recognition\n",
    "## Practice 1\n",
    "\n",
    "### Title: Deep learning advanced architectures\n",
    "\n",
    "The goal is to practice advanced deep learning architectures for multi-label classification in [Pascal VOC dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html). We specifically check ResNet50, Inception and MobileNet. We will see 1) how pretrained ResNet50 on imagenet performs on multi-label images, 2) how to modify classification head and 3) implementation of F1 metric.\n",
    "\n",
    "### NOTES\n",
    "\n",
    "- Hyperparameters are modifiable,\n",
    "- The dataset is PASCAL VOC 2012,\n",
    "- The code uses the KERAS library,\n",
    "- The code can run in google colab.\n",
    "- How to finetune on a pretrained model not included (i.e. freeze the pretrained network and train the head, then finetune everything),\n",
    "- No validation set has been defined. The test and validation sets are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 05:41:28.987335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741326089.005416  613451 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741326089.011045  613451 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-07 05:41:29.029933: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "import tensorflow.keras.applications as app\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing from .py files\n",
    "\n",
    "from metrics import f1_metric, mean_average_precision, subset_accuracy_metric\n",
    "from config import *\n",
    "from experiment_config import experiments\n",
    "from train_and_test import train_and_test\n",
    "from load_data import load_data, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741326092.568221  613451 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:03:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to create datasets: 1.8166263103485107 seconds\n"
     ]
    }
   ],
   "source": [
    "train_list = load_data(TRAIN_TXT)\n",
    "test_list = load_data(TEST_TXT)\n",
    "\n",
    "# Create dictionaries to store datasets for different batch sizes\n",
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "\n",
    "start_time = time.time()\n",
    "# Iterate over batch sizes and create datasets\n",
    "for batch_size in BATCH_SIZES:\n",
    "    train_datasets[batch_size] = create_dataset(\n",
    "        train_list, batch_size, is_training=True\n",
    "    )\n",
    "    test_datasets[batch_size] = create_dataset(test_list, batch_size, is_training=False)\n",
    "print(f\"Time taken to create datasets: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8ej9VbIk_Sfj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model: mobilenet_v2 pretraining no-warmup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613451/3644587405.py:13: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  else mynet(weights=\"imagenet\", include_top=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training loop: mobilenet_v2 pretraining no-warmup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741326108.741813  613451 service.cc:148] XLA service 0x200f21a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741326108.741865  613451 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2025-03-07 05:41:49.108484: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741326110.602709  613451 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-07 05:41:52.645342: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4101', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-03-07 05:41:53.420367: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4101_0', 104 bytes spill stores, 136 bytes spill loads\n",
      "\n",
      "2025-03-07 05:41:54.051647: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4101', 228 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "2025-03-07 05:41:54.773147: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5832', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-03-07 05:41:54.774494: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9549', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-03-07 05:41:54.834955: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9549', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-03-07 05:41:54.841707: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4108', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "2025-03-07 05:41:54.884042: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9549', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1741326129.434566  613451 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training one epoch: 54.63s\n",
      "Epoch 0 training loss: 0.14, acc: 0.92, f1: 0.63, mAP: 0.78\n",
      "Time taken for testing one epoch: 22.80s\n",
      "Epoch 0 test loss: 0.55, acc: 0.74, f1: 0.48, mAP: 0.65\n",
      "Time taken for training one epoch: 44.72s\n",
      "Epoch 1 training loss: 0.09, acc: 0.97, f1: 0.74, mAP: 0.88\n",
      "Time taken for testing one epoch: 22.47s\n",
      "Epoch 1 test loss: 0.45, acc: 0.77, f1: 0.50, mAP: 0.66\n",
      "Time taken for training one epoch: 44.62s\n",
      "Epoch 2 training loss: 0.07, acc: 0.98, f1: 0.80, mAP: 0.92\n",
      "Time taken for testing one epoch: 22.65s\n",
      "Epoch 2 test loss: 0.45, acc: 0.73, f1: 0.24, mAP: 0.55\n",
      "Time taken for training one epoch: 44.71s\n",
      "Epoch 3 training loss: 0.06, acc: 0.99, f1: 0.83, mAP: 0.94\n",
      "Time taken for testing one epoch: 22.61s\n",
      "Epoch 3 test loss: 0.27, acc: 0.82, f1: 0.51, mAP: 0.67\n",
      "Time taken for training one epoch: 44.86s\n",
      "Epoch 4 training loss: 0.05, acc: 0.99, f1: 0.86, mAP: 0.95\n",
      "Time taken for testing one epoch: 22.54s\n",
      "Epoch 4 test loss: 0.38, acc: 0.79, f1: 0.53, mAP: 0.65\n",
      "Time taken for training one epoch: 44.11s\n",
      "Epoch 5 training loss: 0.05, acc: 0.99, f1: 0.87, mAP: 0.96\n",
      "Time taken for testing one epoch: 22.55s\n",
      "Epoch 5 test loss: 0.33, acc: 0.81, f1: 0.45, mAP: 0.63\n",
      "Time taken for training one epoch: 45.13s\n",
      "Epoch 6 training loss: 0.04, acc: 0.99, f1: 0.89, mAP: 0.97\n",
      "Time taken for testing one epoch: 22.48s\n",
      "Epoch 6 test loss: 0.78, acc: 0.71, f1: 0.24, mAP: 0.42\n",
      "Time taken for training one epoch: 44.53s\n",
      "Epoch 7 training loss: 0.04, acc: 0.99, f1: 0.90, mAP: 0.98\n",
      "Time taken for testing one epoch: 22.43s\n",
      "Epoch 7 test loss: 0.38, acc: 0.72, f1: 0.24, mAP: 0.51\n",
      "Time taken for training one epoch: 45.31s\n",
      "Epoch 8 training loss: 0.03, acc: 0.99, f1: 0.91, mAP: 0.98\n",
      "Time taken for testing one epoch: 22.51s\n",
      "Epoch 8 test loss: 0.23, acc: 0.86, f1: 0.50, mAP: 0.67\n",
      "Time taken for training one epoch: 44.52s\n",
      "Epoch 9 training loss: 0.03, acc: 1.00, f1: 0.92, mAP: 0.98\n",
      "Time taken for testing one epoch: 22.46s\n",
      "Epoch 9 test loss: 0.29, acc: 0.83, f1: 0.54, mAP: 0.69\n",
      "Time taken for training one epoch: 45.39s\n",
      "Epoch 10 training loss: 0.02, acc: 1.00, f1: 0.93, mAP: 0.99\n",
      "Time taken for testing one epoch: 21.87s\n",
      "Epoch 10 test loss: 0.50, acc: 0.68, f1: 0.24, mAP: 0.47\n",
      "Time taken for training one epoch: 44.16s\n",
      "Epoch 11 training loss: 0.02, acc: 1.00, f1: 0.94, mAP: 0.99\n",
      "Time taken for testing one epoch: 22.47s\n",
      "Epoch 11 test loss: 0.33, acc: 0.83, f1: 0.54, mAP: 0.67\n",
      "Training (mobilenet_v2 pretraining no-warmup) finished in: 816.82 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/model-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-7-test_subset_acc.csv\n",
      "Current memory usage (bytes): 31775744\n",
      "Peak memory usage (bytes): 1924749056\n",
      "Defining model: mobilenet_v2 pretraining warmup\n",
      "In training loop: mobilenet_v2 pretraining warmup\n",
      "Time taken for training one epoch: 47.09s\n",
      "Epoch 0 training loss: 0.14, acc: 0.91, f1: 0.62, mAP: 0.78\n",
      "Time taken for testing one epoch: 22.48s\n",
      "Epoch 0 test loss: 0.89, acc: 0.72, f1: 0.48, mAP: 0.62\n",
      "Time taken for training one epoch: 44.21s\n",
      "Epoch 1 training loss: 0.09, acc: 0.97, f1: 0.75, mAP: 0.89\n",
      "Time taken for testing one epoch: 22.63s\n",
      "Epoch 1 test loss: 0.56, acc: 0.76, f1: 0.51, mAP: 0.66\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 45.46s\n",
      "Epoch 2 training loss: 0.07, acc: 0.98, f1: 0.80, mAP: 0.92\n",
      "Time taken for testing one epoch: 22.56s\n",
      "Epoch 2 test loss: 0.50, acc: 0.75, f1: 0.48, mAP: 0.65\n",
      "Time taken for training one epoch: 44.46s\n",
      "Epoch 3 training loss: 0.06, acc: 0.99, f1: 0.83, mAP: 0.94\n",
      "Time taken for testing one epoch: 22.52s\n",
      "Epoch 3 test loss: 0.31, acc: 0.80, f1: 0.47, mAP: 0.67\n",
      "Time taken for training one epoch: 44.40s\n",
      "Epoch 4 training loss: 0.05, acc: 0.99, f1: 0.85, mAP: 0.95\n",
      "Time taken for testing one epoch: 22.09s\n",
      "Epoch 4 test loss: 0.36, acc: 0.78, f1: 0.46, mAP: 0.67\n",
      "Time taken for training one epoch: 45.71s\n",
      "Epoch 5 training loss: 0.05, acc: 0.99, f1: 0.87, mAP: 0.96\n",
      "Time taken for testing one epoch: 22.76s\n",
      "Epoch 5 test loss: 0.37, acc: 0.79, f1: 0.50, mAP: 0.65\n",
      "Time taken for training one epoch: 44.76s\n",
      "Epoch 6 training loss: 0.04, acc: 0.99, f1: 0.89, mAP: 0.97\n",
      "Time taken for testing one epoch: 22.14s\n",
      "Epoch 6 test loss: 0.47, acc: 0.66, f1: 0.18, mAP: 0.44\n",
      "Time taken for training one epoch: 44.65s\n",
      "Epoch 7 training loss: 0.04, acc: 0.99, f1: 0.90, mAP: 0.98\n",
      "Time taken for testing one epoch: 22.73s\n",
      "Epoch 7 test loss: 0.44, acc: 0.70, f1: 0.20, mAP: 0.53\n",
      "Time taken for training one epoch: 44.99s\n",
      "Epoch 8 training loss: 0.03, acc: 1.00, f1: 0.91, mAP: 0.98\n",
      "Time taken for testing one epoch: 22.65s\n",
      "Epoch 8 test loss: 0.34, acc: 0.82, f1: 0.56, mAP: 0.71\n",
      "Time taken for training one epoch: 45.94s\n",
      "Epoch 9 training loss: 0.03, acc: 1.00, f1: 0.93, mAP: 0.98\n",
      "Time taken for testing one epoch: 22.64s\n",
      "Epoch 9 test loss: 0.42, acc: 0.74, f1: 0.34, mAP: 0.55\n",
      "Time taken for training one epoch: 44.60s\n",
      "Epoch 10 training loss: 0.03, acc: 1.00, f1: 0.93, mAP: 0.98\n",
      "Time taken for testing one epoch: 22.71s\n",
      "Epoch 10 test loss: 0.33, acc: 0.81, f1: 0.45, mAP: 0.63\n",
      "Time taken for training one epoch: 44.52s\n",
      "Epoch 11 training loss: 0.02, acc: 1.00, f1: 0.94, mAP: 0.99\n",
      "Time taken for testing one epoch: 22.62s\n",
      "Epoch 11 test loss: 0.36, acc: 0.75, f1: 0.33, mAP: 0.51\n",
      "Training (mobilenet_v2 pretraining warmup) finished in: 811.64 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/model-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/mobilenet_v2-8-test_subset_acc.csv\n",
      "Current memory usage (bytes): 63737088\n",
      "Peak memory usage (bytes): 1956695808\n"
     ]
    }
   ],
   "source": [
    "# Run model experiments\n",
    "exp_name = \"model-experiments\"\n",
    "for exp in experiments[exp_name][7:]:\n",
    "    print(f\"Defining model: {exp.title}\")\n",
    "\n",
    "    # Select the corresponding network class\n",
    "    mynet = getattr(getattr(app, exp.net_name[0]), exp.net_name[1])\n",
    "\n",
    "    # Create the base pre-trained model\n",
    "    base_model = (\n",
    "        mynet(include_top=False)\n",
    "        if exp.train_from_scratch\n",
    "        else mynet(weights=\"imagenet\", include_top=False)\n",
    "    )\n",
    "\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "    predictions = Dense(num_classes, activation=exp.last_layer_activation)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model, exp_name, exp, train_dataset, test_dataset, train_list, test_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentConfig(id=2, title='resnet50 pretraining warmup', net_name=['resnet50', 'ResNet50'], train_from_scratch=False, warm_up=True, batch_size=32, n_epochs=12, last_layer_activation='sigmoid', learning_rate=0.001, loss='binary_crossentropy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Determine the best experiment of the 9 model experiments\n",
    "\n",
    "df = pd.read_csv(RESULTS_DIR / f\"model-experiments.csv\")\n",
    "best_id = df.loc[df[\"Test mAP\"].idxmax(), \"ID\"]\n",
    "\n",
    "best_model_experiment_config = next(\n",
    "    exp for exp in experiments[\"model-experiments\"] if exp.id == best_id\n",
    ")\n",
    "\n",
    "best_model_experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model: batch_size: 16, learning_rate: 0.001\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 16, learning_rate: 0.001\n",
      "Time taken for training one epoch: 78.57s\n",
      "Epoch 0 training loss: 0.18, acc: 0.87, f1: 0.51, mAP: 0.70\n",
      "Time taken for testing one epoch: 39.64s\n",
      "Epoch 0 test loss: 0.19, acc: 0.87, f1: 0.36, mAP: 0.62\n",
      "Time taken for training one epoch: 68.56s\n",
      "Epoch 1 training loss: 0.11, acc: 0.95, f1: 0.67, mAP: 0.83\n",
      "Time taken for testing one epoch: 39.49s\n",
      "Epoch 1 test loss: 0.17, acc: 0.90, f1: 0.57, mAP: 0.74\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 68.15s\n",
      "Epoch 2 training loss: 0.08, acc: 0.97, f1: 0.76, mAP: 0.89\n",
      "Time taken for testing one epoch: 39.61s\n",
      "Epoch 2 test loss: 0.21, acc: 0.88, f1: 0.52, mAP: 0.71\n",
      "Time taken for training one epoch: 70.75s\n",
      "Epoch 3 training loss: 0.07, acc: 0.98, f1: 0.81, mAP: 0.92\n",
      "Time taken for testing one epoch: 39.77s\n",
      "Epoch 3 test loss: 0.18, acc: 0.90, f1: 0.57, mAP: 0.73\n",
      "Time taken for training one epoch: 68.89s\n",
      "Epoch 4 training loss: 0.05, acc: 0.99, f1: 0.85, mAP: 0.95\n",
      "Time taken for testing one epoch: 39.84s\n",
      "Epoch 4 test loss: 0.25, acc: 0.86, f1: 0.59, mAP: 0.74\n",
      "Time taken for training one epoch: 68.67s\n",
      "Epoch 5 training loss: 0.04, acc: 0.99, f1: 0.88, mAP: 0.97\n",
      "Time taken for testing one epoch: 39.76s\n",
      "Epoch 5 test loss: 0.29, acc: 0.80, f1: 0.40, mAP: 0.59\n",
      "Time taken for training one epoch: 68.90s\n",
      "Epoch 6 training loss: 0.03, acc: 1.00, f1: 0.91, mAP: 0.98\n",
      "Time taken for testing one epoch: 39.64s\n",
      "Epoch 6 test loss: 0.18, acc: 0.91, f1: 0.65, mAP: 0.79\n",
      "Time taken for training one epoch: 68.70s\n",
      "Epoch 7 training loss: 0.03, acc: 1.00, f1: 0.93, mAP: 0.98\n",
      "Time taken for testing one epoch: 42.24s\n",
      "Epoch 7 test loss: 0.20, acc: 0.91, f1: 0.64, mAP: 0.78\n",
      "Time taken for training one epoch: 69.02s\n",
      "Epoch 8 training loss: 0.02, acc: 1.00, f1: 0.95, mAP: 0.99\n",
      "Time taken for testing one epoch: 39.73s\n",
      "Epoch 8 test loss: 0.21, acc: 0.90, f1: 0.65, mAP: 0.79\n",
      "Time taken for training one epoch: 68.92s\n",
      "Epoch 9 training loss: 0.02, acc: 1.00, f1: 0.96, mAP: 0.99\n",
      "Time taken for testing one epoch: 39.70s\n",
      "Epoch 9 test loss: 0.27, acc: 0.88, f1: 0.63, mAP: 0.77\n",
      "Time taken for training one epoch: 69.01s\n",
      "Epoch 10 training loss: 0.01, acc: 1.00, f1: 0.97, mAP: 1.00\n",
      "Time taken for testing one epoch: 39.60s\n",
      "Epoch 10 test loss: 0.25, acc: 0.87, f1: 0.59, mAP: 0.74\n",
      "Time taken for training one epoch: 69.00s\n",
      "Epoch 11 training loss: 0.01, acc: 1.00, f1: 0.97, mAP: 1.00\n",
      "Time taken for testing one epoch: 39.56s\n",
      "Epoch 11 test loss: 0.23, acc: 0.90, f1: 0.66, mAP: 0.80\n",
      "Training (batch_size: 16, learning_rate: 0.001) finished in: 1316.06 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-9-test_subset_acc.csv\n",
      "Current memory usage (bytes): 294446592\n",
      "Peak memory usage (bytes): 1956695808\n",
      "Defining model: batch_size: 16, learning_rate: 0.01\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 16, learning_rate: 0.01\n",
      "Time taken for training one epoch: 72.16s\n",
      "Epoch 0 training loss: 0.35, acc: 0.73, f1: 0.36, mAP: 0.55\n",
      "Time taken for testing one epoch: 39.48s\n",
      "Epoch 0 test loss: 0.20, acc: 0.78, f1: 0.46, mAP: 0.57\n",
      "Time taken for training one epoch: 68.60s\n",
      "Epoch 1 training loss: 0.20, acc: 0.76, f1: 0.44, mAP: 0.58\n",
      "Time taken for testing one epoch: 39.59s\n",
      "Epoch 1 test loss: 0.20, acc: 0.79, f1: 0.48, mAP: 0.57\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 68.34s\n",
      "Epoch 2 training loss: 0.20, acc: 0.77, f1: 0.45, mAP: 0.59\n",
      "Time taken for testing one epoch: 39.65s\n",
      "Epoch 2 test loss: 0.20, acc: 0.81, f1: 0.46, mAP: 0.59\n",
      "Time taken for training one epoch: 68.62s\n",
      "Epoch 3 training loss: 0.19, acc: 0.79, f1: 0.45, mAP: 0.59\n",
      "Time taken for testing one epoch: 39.68s\n",
      "Epoch 3 test loss: 0.20, acc: 0.82, f1: 0.47, mAP: 0.59\n",
      "Time taken for training one epoch: 68.69s\n",
      "Epoch 4 training loss: 0.19, acc: 0.80, f1: 0.44, mAP: 0.60\n",
      "Time taken for testing one epoch: 39.62s\n",
      "Epoch 4 test loss: 0.20, acc: 0.82, f1: 0.43, mAP: 0.59\n",
      "Time taken for training one epoch: 72.00s\n",
      "Epoch 5 training loss: 0.19, acc: 0.81, f1: 0.45, mAP: 0.60\n",
      "Time taken for testing one epoch: 39.93s\n",
      "Epoch 5 test loss: 0.20, acc: 0.82, f1: 0.48, mAP: 0.59\n",
      "Time taken for training one epoch: 68.72s\n",
      "Epoch 6 training loss: 0.19, acc: 0.81, f1: 0.45, mAP: 0.61\n",
      "Time taken for testing one epoch: 39.75s\n",
      "Epoch 6 test loss: 0.20, acc: 0.81, f1: 0.48, mAP: 0.58\n",
      "Time taken for training one epoch: 68.63s\n",
      "Epoch 7 training loss: 0.19, acc: 0.82, f1: 0.45, mAP: 0.61\n",
      "Time taken for testing one epoch: 39.74s\n",
      "Epoch 7 test loss: 0.19, acc: 0.84, f1: 0.46, mAP: 0.61\n",
      "Time taken for training one epoch: 68.56s\n",
      "Epoch 8 training loss: 0.19, acc: 0.83, f1: 0.44, mAP: 0.62\n",
      "Time taken for testing one epoch: 39.59s\n",
      "Epoch 8 test loss: 0.19, acc: 0.84, f1: 0.46, mAP: 0.61\n",
      "Time taken for training one epoch: 68.76s\n",
      "Epoch 9 training loss: 0.18, acc: 0.84, f1: 0.44, mAP: 0.62\n",
      "Time taken for testing one epoch: 39.03s\n",
      "Epoch 9 test loss: 0.20, acc: 0.83, f1: 0.39, mAP: 0.60\n",
      "Time taken for training one epoch: 68.49s\n",
      "Epoch 10 training loss: 0.18, acc: 0.84, f1: 0.44, mAP: 0.63\n",
      "Time taken for testing one epoch: 39.69s\n",
      "Epoch 10 test loss: 0.19, acc: 0.85, f1: 0.41, mAP: 0.61\n",
      "Time taken for training one epoch: 68.76s\n",
      "Epoch 11 training loss: 0.18, acc: 0.85, f1: 0.43, mAP: 0.63\n",
      "Time taken for testing one epoch: 39.48s\n",
      "Epoch 11 test loss: 0.19, acc: 0.84, f1: 0.42, mAP: 0.62\n",
      "Training (batch_size: 16, learning_rate: 0.01) finished in: 1305.87 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-10-test_subset_acc.csv\n",
      "Current memory usage (bytes): 525225728\n",
      "Peak memory usage (bytes): 1988659968\n",
      "Defining model: batch_size: 16, learning_rate: 0.1\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 16, learning_rate: 0.1\n",
      "Time taken for training one epoch: 71.08s\n",
      "Epoch 0 training loss: 4.98, acc: 0.73, f1: 0.41, mAP: 0.56\n",
      "Time taken for testing one epoch: 38.98s\n",
      "Epoch 0 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.03s\n",
      "Epoch 1 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.78s\n",
      "Epoch 1 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 67.72s\n",
      "Epoch 2 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.03s\n",
      "Epoch 2 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.23s\n",
      "Epoch 3 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.70s\n",
      "Epoch 3 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.11s\n",
      "Epoch 4 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.27s\n",
      "Epoch 4 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.14s\n",
      "Epoch 5 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.67s\n",
      "Epoch 5 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.46s\n",
      "Epoch 6 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.55s\n",
      "Epoch 6 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 71.69s\n",
      "Epoch 7 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.85s\n",
      "Epoch 7 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.33s\n",
      "Epoch 8 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.65s\n",
      "Epoch 8 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.34s\n",
      "Epoch 9 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.20s\n",
      "Epoch 9 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.23s\n",
      "Epoch 10 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.76s\n",
      "Epoch 10 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.35s\n",
      "Epoch 11 training loss: 0.20, acc: 0.75, f1: 0.44, mAP: 0.57\n",
      "Time taken for testing one epoch: 39.81s\n",
      "Epoch 11 test loss: 0.21, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Training (batch_size: 16, learning_rate: 0.1) finished in: 1290.30 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-11-test_subset_acc.csv\n",
      "Current memory usage (bytes): 763842048\n",
      "Peak memory usage (bytes): 2217428992\n",
      "Defining model: batch_size: 32, learning_rate: 0.001\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 32, learning_rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 07:14:51.522661: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6302_0', 112 bytes spill stores, 224 bytes spill loads\n",
      "\n",
      "2025-03-07 07:14:51.647094: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6785', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-03-07 07:14:51.719335: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11157', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2025-03-07 07:14:51.776295: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11157', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-03-07 07:14:51.907243: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11157', 24 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-03-07 07:14:52.008448: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6302', 192 bytes spill stores, 512 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training one epoch: 78.97s\n",
      "Epoch 0 training loss: 0.17, acc: 0.89, f1: 0.56, mAP: 0.74\n",
      "Time taken for testing one epoch: 25.08s\n",
      "Epoch 0 test loss: 0.24, acc: 0.74, f1: 0.04, mAP: 0.44\n",
      "Time taken for training one epoch: 67.70s\n",
      "Epoch 1 training loss: 0.09, acc: 0.97, f1: 0.74, mAP: 0.88\n",
      "Time taken for testing one epoch: 25.03s\n",
      "Epoch 1 test loss: 0.18, acc: 0.90, f1: 0.57, mAP: 0.72\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 67.36s\n",
      "Epoch 2 training loss: 0.07, acc: 0.98, f1: 0.81, mAP: 0.93\n",
      "Time taken for testing one epoch: 25.02s\n",
      "Epoch 2 test loss: 0.40, acc: 0.73, f1: 0.21, mAP: 0.48\n",
      "Time taken for training one epoch: 67.44s\n",
      "Epoch 3 training loss: 0.05, acc: 0.99, f1: 0.86, mAP: 0.95\n",
      "Time taken for testing one epoch: 24.48s\n",
      "Epoch 3 test loss: 0.24, acc: 0.86, f1: 0.53, mAP: 0.70\n",
      "Time taken for training one epoch: 67.61s\n",
      "Epoch 4 training loss: 0.04, acc: 0.99, f1: 0.89, mAP: 0.97\n",
      "Time taken for testing one epoch: 25.05s\n",
      "Epoch 4 test loss: 0.26, acc: 0.86, f1: 0.52, mAP: 0.71\n",
      "Time taken for training one epoch: 67.45s\n",
      "Epoch 5 training loss: 0.03, acc: 1.00, f1: 0.91, mAP: 0.98\n",
      "Time taken for testing one epoch: 25.10s\n",
      "Epoch 5 test loss: 0.18, acc: 0.90, f1: 0.62, mAP: 0.77\n",
      "Time taken for training one epoch: 67.52s\n",
      "Epoch 6 training loss: 0.02, acc: 1.00, f1: 0.93, mAP: 0.99\n",
      "Time taken for testing one epoch: 25.11s\n",
      "Epoch 6 test loss: 0.27, acc: 0.87, f1: 0.62, mAP: 0.76\n",
      "Time taken for training one epoch: 67.57s\n",
      "Epoch 7 training loss: 0.02, acc: 1.00, f1: 0.95, mAP: 0.99\n",
      "Time taken for testing one epoch: 25.07s\n",
      "Epoch 7 test loss: 0.34, acc: 0.81, f1: 0.52, mAP: 0.70\n",
      "Time taken for training one epoch: 67.43s\n",
      "Epoch 8 training loss: 0.02, acc: 1.00, f1: 0.96, mAP: 0.99\n",
      "Time taken for testing one epoch: 25.00s\n",
      "Epoch 8 test loss: 0.22, acc: 0.89, f1: 0.70, mAP: 0.83\n",
      "Time taken for training one epoch: 67.76s\n",
      "Epoch 9 training loss: 0.01, acc: 1.00, f1: 0.97, mAP: 1.00\n",
      "Time taken for testing one epoch: 31.18s\n",
      "Epoch 9 test loss: 0.25, acc: 0.88, f1: 0.67, mAP: 0.81\n",
      "Time taken for training one epoch: 68.07s\n",
      "Epoch 10 training loss: 0.01, acc: 1.00, f1: 0.97, mAP: 1.00\n",
      "Time taken for testing one epoch: 25.12s\n",
      "Epoch 10 test loss: 0.26, acc: 0.89, f1: 0.67, mAP: 0.81\n",
      "Time taken for training one epoch: 67.62s\n",
      "Epoch 11 training loss: 0.01, acc: 1.00, f1: 0.98, mAP: 1.00\n",
      "Time taken for testing one epoch: 25.08s\n",
      "Epoch 11 test loss: 0.25, acc: 0.87, f1: 0.64, mAP: 0.79\n",
      "Training (batch_size: 32, learning_rate: 0.001) finished in: 1129.11 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-12-test_subset_acc.csv\n",
      "Current memory usage (bytes): 1002181632\n",
      "Peak memory usage (bytes): 3783042560\n",
      "Defining model: batch_size: 32, learning_rate: 0.01\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 32, learning_rate: 0.01\n",
      "Time taken for training one epoch: 70.33s\n",
      "Epoch 0 training loss: 0.38, acc: 0.72, f1: 0.37, mAP: 0.56\n",
      "Time taken for testing one epoch: 24.84s\n",
      "Epoch 0 test loss: 0.21, acc: 0.75, f1: 0.00, mAP: 0.55\n",
      "Time taken for training one epoch: 67.17s\n",
      "Epoch 1 training loss: 0.20, acc: 0.78, f1: 0.41, mAP: 0.59\n",
      "Time taken for testing one epoch: 25.03s\n",
      "Epoch 1 test loss: 0.22, acc: 0.73, f1: 0.03, mAP: 0.55\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 66.95s\n",
      "Epoch 2 training loss: 0.19, acc: 0.81, f1: 0.43, mAP: 0.60\n",
      "Time taken for testing one epoch: 25.03s\n",
      "Epoch 2 test loss: 0.20, acc: 0.83, f1: 0.40, mAP: 0.60\n",
      "Time taken for training one epoch: 67.30s\n",
      "Epoch 3 training loss: 0.19, acc: 0.83, f1: 0.44, mAP: 0.61\n",
      "Time taken for testing one epoch: 25.00s\n",
      "Epoch 3 test loss: 0.20, acc: 0.83, f1: 0.40, mAP: 0.60\n",
      "Time taken for training one epoch: 67.22s\n",
      "Epoch 4 training loss: 0.18, acc: 0.84, f1: 0.44, mAP: 0.62\n",
      "Time taken for testing one epoch: 24.99s\n",
      "Epoch 4 test loss: 0.19, acc: 0.84, f1: 0.39, mAP: 0.61\n",
      "Time taken for training one epoch: 67.17s\n",
      "Epoch 5 training loss: 0.18, acc: 0.85, f1: 0.43, mAP: 0.63\n",
      "Time taken for testing one epoch: 24.98s\n",
      "Epoch 5 test loss: 0.19, acc: 0.84, f1: 0.37, mAP: 0.61\n",
      "Time taken for training one epoch: 67.17s\n",
      "Epoch 6 training loss: 0.18, acc: 0.85, f1: 0.43, mAP: 0.63\n",
      "Time taken for testing one epoch: 24.96s\n",
      "Epoch 6 test loss: 0.19, acc: 0.84, f1: 0.30, mAP: 0.61\n",
      "Time taken for training one epoch: 67.69s\n",
      "Epoch 7 training loss: 0.18, acc: 0.86, f1: 0.44, mAP: 0.64\n",
      "Time taken for testing one epoch: 26.55s\n",
      "Epoch 7 test loss: 0.19, acc: 0.86, f1: 0.38, mAP: 0.62\n",
      "Time taken for training one epoch: 68.14s\n",
      "Epoch 8 training loss: 0.17, acc: 0.87, f1: 0.44, mAP: 0.64\n",
      "Time taken for testing one epoch: 25.32s\n",
      "Epoch 8 test loss: 0.20, acc: 0.84, f1: 0.34, mAP: 0.61\n",
      "Time taken for training one epoch: 67.74s\n",
      "Epoch 9 training loss: 0.17, acc: 0.88, f1: 0.45, mAP: 0.65\n",
      "Time taken for testing one epoch: 25.16s\n",
      "Epoch 9 test loss: 0.19, acc: 0.86, f1: 0.32, mAP: 0.62\n",
      "Time taken for training one epoch: 68.10s\n",
      "Epoch 10 training loss: 0.17, acc: 0.88, f1: 0.45, mAP: 0.66\n",
      "Time taken for testing one epoch: 25.13s\n",
      "Epoch 10 test loss: 0.21, acc: 0.83, f1: 0.25, mAP: 0.57\n",
      "Time taken for training one epoch: 68.00s\n",
      "Epoch 11 training loss: 0.16, acc: 0.89, f1: 0.46, mAP: 0.68\n",
      "Time taken for testing one epoch: 24.60s\n",
      "Epoch 11 test loss: 0.20, acc: 0.85, f1: 0.32, mAP: 0.60\n",
      "Training (batch_size: 32, learning_rate: 0.01) finished in: 1114.92 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-13-test_subset_acc.csv\n",
      "Current memory usage (bytes): 1232659200\n",
      "Peak memory usage (bytes): 4017192448\n",
      "Defining model: batch_size: 32, learning_rate: 0.1\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 32, learning_rate: 0.1\n",
      "Time taken for training one epoch: 72.25s\n",
      "Epoch 0 training loss: 10.62, acc: 0.72, f1: 0.38, mAP: 0.56\n",
      "Time taken for testing one epoch: 24.75s\n",
      "Epoch 0 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 68.01s\n",
      "Epoch 1 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 25.33s\n",
      "Epoch 1 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Unfreezing base model at epoch 2\n",
      "Time taken for training one epoch: 67.84s\n",
      "Epoch 2 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 25.33s\n",
      "Epoch 2 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.46s\n",
      "Epoch 3 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 24.44s\n",
      "Epoch 3 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.33s\n",
      "Epoch 4 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 24.52s\n",
      "Epoch 4 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 69.31s\n",
      "Epoch 5 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 25.78s\n",
      "Epoch 5 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.35s\n",
      "Epoch 6 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 25.28s\n",
      "Epoch 6 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.88s\n",
      "Epoch 7 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 25.27s\n",
      "Epoch 7 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.57s\n",
      "Epoch 8 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 25.41s\n",
      "Epoch 8 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.16s\n",
      "Epoch 9 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 24.71s\n",
      "Epoch 9 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 67.28s\n",
      "Epoch 10 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 25.22s\n",
      "Epoch 10 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Time taken for training one epoch: 66.92s\n",
      "Epoch 11 training loss: 0.20, acc: 0.75, f1: 0.45, mAP: 0.57\n",
      "Time taken for testing one epoch: 25.24s\n",
      "Epoch 11 test loss: 0.20, acc: 0.77, f1: 0.49, mAP: 0.56\n",
      "Training (batch_size: 32, learning_rate: 0.1) finished in: 1117.95 seconds\n",
      "Results saved to /root/mai-object-recognition/practicals/p1/data/02_results/hyperparameter-experiments.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-train_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-train_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-train_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-train_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-train_subset_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-test_loss.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-test_acc.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-test_f1.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-test_map.csv\n",
      "History saved to /root/mai-object-recognition/practicals/p1/data/01_histories/resnet50-14-test_subset_acc.csv\n",
      "Current memory usage (bytes): 1461251072\n",
      "Peak memory usage (bytes): 4244628736\n",
      "Defining model: batch_size: 64, learning_rate: 0.001\n",
      "Reusing net_name: ['resnet50', 'ResNet50'], train_from_scratch: False, warm_up: True from best model experiment\n",
      "In training loop: batch_size: 64, learning_rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 08:11:49.450768: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6300_0', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2025-03-07 08:11:50.006851: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6300', 192 bytes spill stores, 512 bytes spill loads\n",
      "\n",
      "2025-03-07 08:11:50.846266: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6791', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-03-07 08:11:51.758404: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11163', 496 bytes spill stores, 496 bytes spill loads\n",
      "\n",
      "2025-03-07 08:11:52.012772: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6307', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "2025-03-07 08:11:52.422675: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11163', 440 bytes spill stores, 440 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training one epoch: 86.91s\n",
      "Epoch 0 training loss: 0.18, acc: 0.88, f1: 0.58, mAP: 0.74\n",
      "Time taken for testing one epoch: 18.99s\n",
      "Epoch 0 test loss: 0.28, acc: 0.70, f1: 0.00, mAP: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter experiments\n",
    "\n",
    "exp_name = \"hyperparameter-experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "    print(f\"Defining model: {exp.title}\")\n",
    "    print(\n",
    "        f\"Reusing net_name: {best_model_experiment_config.net_name}, train_from_scratch: {best_model_experiment_config.train_from_scratch}, warm_up: {best_model_experiment_config.warm_up} from best model experiment\"\n",
    "    )\n",
    "    exp.net_name = best_model_experiment_config.net_name\n",
    "    exp.train_from_scratch = best_model_experiment_config.train_from_scratch\n",
    "    exp.warm_up = best_model_experiment_config.warm_up\n",
    "\n",
    "    # Select the corresponding network class\n",
    "    mynet = getattr(getattr(app, exp.net_name[0]), exp.net_name[1])\n",
    "\n",
    "    # Create the base pre-trained model\n",
    "    base_model = (\n",
    "        mynet(include_top=False)\n",
    "        if exp.train_from_scratch\n",
    "        else mynet(weights=\"imagenet\", include_top=False)\n",
    "    )\n",
    "\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "    predictions = Dense(num_classes, activation=exp.last_layer_activation)(x)\n",
    "\n",
    "      # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model, exp_name, exp, train_dataset, test_dataset, train_list, test_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best experiment of the 9 hyperparameter experiments\n",
    "\n",
    "df = pd.read_csv(RESULTS_DIR / f\"hyperparameter-experiments.csv\")\n",
    "best_id = df.loc[df[\"Test mAP\"].idxmax(), \"ID\"]\n",
    "\n",
    "best_hyperparameter_experiment_config = next(\n",
    "    exp for exp in experiments[\"hyperparameter-experiments\"] if exp.id == best_id\n",
    ")\n",
    "\n",
    "best_hyperparameter_experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run augmentation experiments\n",
    "\n",
    "exp_name = \"augmentation-experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "    print(f\"Defining model: {exp.title}\")\n",
    "    print(\n",
    "        f\"Reusing net_name: {best_hyperparameter_experiment_config.net_name}, train_from_scratch: {best_hyperparameter_experiment_config.train_from_scratch}, warm_up: {best_hyperparameter_experiment_config.warm_up} from best hyperparameter experiment\"\n",
    "    )\n",
    "    exp.net_name = best_hyperparameter_experiment_config.net_name\n",
    "    exp.train_from_scratch = best_hyperparameter_experiment_config.train_from_scratch\n",
    "    exp.warm_up = best_hyperparameter_experiment_config.warm_up\n",
    "    exp.batch_size = best_hyperparameter_experiment_config.batch_size\n",
    "    exp.learning_rate = best_hyperparameter_experiment_config.learning_rate\n",
    "    exp.loss = best_hyperparameter_experiment_config.loss\n",
    "    exp.last_layer_activation = (\n",
    "        best_hyperparameter_experiment_config.last_layer_activation\n",
    "    )\n",
    "\n",
    "    # Select the corresponding network class\n",
    "    mynet = getattr(getattr(app, exp.net_name[0]), exp.net_name[1])\n",
    "\n",
    "    # Create the base pre-trained model\n",
    "    base_model = (\n",
    "        mynet(include_top=False)\n",
    "        if exp.train_from_scratch\n",
    "        else mynet(weights=\"imagenet\", include_top=False)\n",
    "    )\n",
    "\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "    predictions = Dense(num_classes, activation=exp.last_layer_activation)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model, exp_name, exp, train_dataset, test_dataset, train_list, test_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier head experiments\n",
    "\n",
    "exp_name = \"classfier_head_experiments\"\n",
    "for exp in experiments[exp_name]:\n",
    "    print(f\"Defining model: {exp.title}\")\n",
    "    print(\n",
    "        f\"Reusing net_name: {best_hyperparameter_experiment_config.net_name}, train_from_scratch: {best_hyperparameter_experiment_config.train_from_scratch}, warm_up: {best_hyperparameter_experiment_config.warm_up} from best hyperparameter experiment\"\n",
    "    )\n",
    "    exp.net_name = best_hyperparameter_experiment_config.net_name\n",
    "    exp.train_from_scratch = best_hyperparameter_experiment_config.train_from_scratch\n",
    "    exp.warm_up = best_hyperparameter_experiment_config.warm_up\n",
    "    exp.batch_size = best_hyperparameter_experiment_config.batch_size\n",
    "    exp.learning_rate = best_hyperparameter_experiment_config.learning_rate\n",
    "    exp.loss = best_hyperparameter_experiment_config.loss\n",
    "    exp.last_layer_activation = (\n",
    "        best_hyperparameter_experiment_config.last_layer_activation\n",
    "    )\n",
    "\n",
    "    # Select the corresponding network class\n",
    "    mynet = getattr(getattr(app, exp.net_name[0]), exp.net_name[1])\n",
    "\n",
    "    # Create the base pre-trained model\n",
    "    base_model = (\n",
    "        mynet(include_top=False)\n",
    "        if exp.train_from_scratch\n",
    "        else mynet(weights=\"imagenet\", include_top=False)\n",
    "    )\n",
    "\n",
    "    # Add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "    predictions = Dense(num_classes, activation=exp.last_layer_activation)(x)\n",
    "\n",
    "        # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    train_dataset = train_datasets[exp.batch_size]\n",
    "    test_dataset = test_datasets[exp.batch_size]\n",
    "\n",
    "    train_and_test(\n",
    "        model, exp_name, exp, train_dataset, test_dataset, train_list, test_list\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
