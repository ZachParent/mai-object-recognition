\begin{table}[h!]
\caption{Results for all experiments. Best model from each experiment set shown in bold.}
\label{tab:all\_results}
\begin{tabular}{lrrrrrrrrrrrr}
 & Experiment Set & Model & Test Loss & Test Accuracy & Test F1 Score & Test mAP \\
0 & model-experiments & resnet50 no-pretraining no-warmup & 0.2417 & 0.8806 & 0.6842 & 0.8215 \\
1 & model-experiments & resnet50 pretraining no-warmup & 0.1988 & 0.9018 & 0.6658 & 0.8169 \\
2 & model-experiments & resnet50 pretraining warmup & 0.2253 & 0.8721 & 0.6115 & 0.7661 \\
3 & model-experiments & inception\_v3 no-pretraining no-warmup & 0.2269 & 0.8698 & 0.6650 & 0.7993 \\
4 & model-experiments & inception\_v3 pretraining no-warmup & 0.1727 & 0.9137 & 0.6954 & 0.8353 \\
5 & model-experiments & inception\_v3 pretraining warmup & 0.1889 & 0.8985 & 0.6532 & 0.8036 \\
6 & model-experiments & mobilenet\_v2 no-pretraining no-warmup & 0.4132 & 0.6947 & 0.2586 & 0.4897 \\
7 & model-experiments & mobilenet\_v2 pretraining no-warmup & 0.3973 & 0.7572 & 0.3768 & 0.5803 \\
8 & model-experiments & mobilenet\_v2 pretraining warmup & 0.2647 & 0.8256 & 0.5424 & 0.6917 \\
9 & hyperparameter-experiments & batch\_size=16, learning\_rate=0.0001 & 0.1652 & 0.9240 & 0.7779 & 0.8997 \\
10 & hyperparameter-experiments & batch\_size=16, learning\_rate=0.001 & 0.1787 & 0.8994 & 0.6376 & 0.7836 \\
11 & hyperparameter-experiments & batch\_size=16, learning\_rate=0.01 & 0.2010 & 0.7925 & 0.3092 & 0.5865 \\
12 & hyperparameter-experiments & batch\_size=32, learning\_rate=0.0001 & 0.1399 & 0.9294 & 0.7905 & 0.9118 \\
13 & hyperparameter-experiments & batch\_size=32, learning\_rate=0.001 & 0.2596 & 0.8531 & 0.5439 & 0.7050 \\
14 & hyperparameter-experiments & batch\_size=32, learning\_rate=0.01 & 0.2534 & 0.8491 & 0.4387 & 0.6339 \\
15 & hyperparameter-experiments & batch\_size=64, learning\_rate=0.0001 & 0.1251 & 0.9315 & 0.7977 & 0.9118 \\
16 & hyperparameter-experiments & batch\_size=64, learning\_rate=0.001 & 0.2009 & 0.8926 & 0.7222 & 0.8543 \\
17 & hyperparameter-experiments & batch\_size=64, learning\_rate=0.01 & 0.1912 & 0.8308 & 0.4596 & 0.6104 \\
18 & classifier\_head-experiments & classifier\_head=ensemble & 0.1187 & 0.9388 & 0.7973 & 0.9169 \\
19 & classifier\_head-experiments & classifier\_head=attention & 0.1379 & 0.9261 & 0.7824 & 0.8975 \\
20 & augmentation-experiments & augmentation=simple & 0.1381 & 0.9279 & 0.7972 & 0.9131 \\
21 & augmentation-experiments & augmentation=color & 0.1337 & 0.9314 & 0.7985 & 0.9113 \\
22 & augmentation-experiments & augmentation=occlusion & 0.1341 & 0.9307 & 0.7951 & 0.9124 \\
23 & augmentation-experiments & augmentation=all & 0.1356 & 0.9299 & 0.7950 & 0.9130 \\
24 & imbalance-experiments & imbalance\_handling=loss & 4.1940 & 0.9043 & 0.7772 & 0.8914 \\
25 & imbalance-experiments & imbalance\_handling=batch & 0.1403 & 0.9264 & 0.7965 & 0.9139 \\
26 & optimized & optimized & 0.1212 & 0.9379 & 0.8010 & 0.9172 \\
\end{tabular}
\end{table}
