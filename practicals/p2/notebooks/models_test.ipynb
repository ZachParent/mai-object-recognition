{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanch\\Desktop\\MAI\\Semester2\\OR\\Deliverables\\mai-object-recognition\\.venv_p2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchmetrics.classification import Accuracy, Dice\n",
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from data_load_test import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the GPU\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # Use the CPU\n",
    "    print(\"GPU is not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes: 28\n",
      "loading annotations into memory...\n",
      "Done (t=5.86s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 45622 images containing main garment categories\n",
      "loading annotations into memory...\n",
      "Done (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 1158 images containing main garment categories\n",
      "Number of training batches: 11405\n",
      "Number of validation batches: 290\n"
     ]
    }
   ],
   "source": [
    "# Ask for dataset directory\n",
    "data_dir = \"../data/00_raw\"\n",
    "\n",
    "# Setup paths\n",
    "data_paths = setup_fashionpedia(data_dir)\n",
    "\n",
    "# Load category mappings\n",
    "category_mappings = load_fashionpedia_categories(data_paths['train_ann_file'])\n",
    "print(f\"Total number of classes: {category_mappings['num_classes']}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, val_loader = create_data_loaders(data_paths, category_mappings, batch_size=4)\n",
    "\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 28\n",
    "\n",
    "def choose_model(model_name):\n",
    "    if model_name == 'deeplab':\n",
    "        # Load the pre-trained DeepLabv3 model\n",
    "        model = models.segmentation.deeplabv3_resnet101(weights_backbone=\"ResNet101_Weights.DEFAULT\", num_classes=num_classes)\n",
    "        model.to(device)\n",
    "        return model\n",
    "    elif model_name == 'segformer':\n",
    "        # Load the pre-trained SegFormer feature extractor\n",
    "        # feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "\n",
    "        # Load the pre-trained SegFormer model with the specified number of classes\n",
    "        model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\", num_labels=num_classes, ignore_mismatched_sizes=True)\n",
    "        model.to(device)\n",
    "        return model\n",
    "    elif model_name == 'lraspp':\n",
    "        # Load the pre-trained LR-ASPP model\n",
    "        model = models.segmentation.lraspp_mobilenet_v3_large(weights_backbone=\"MobileNet_V3_Large_Weights.DEFAULT\", num_classes=num_classes)\n",
    "        model.to(device)\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model name: {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_options = [\"deeplab\", \"segformer\", \"lraspp\"]\n",
    "model = choose_model(model_options[2])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "mDice = Dice(average='macro', num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Training and Evaluation\n",
    "\n",
    "# Train and test functions\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    correct, total, running_loss = 0, 0, 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training\", unit=\"batch\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)['out']\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Store predictions and labels as tensors\n",
    "        all_preds.append(predicted.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "    \n",
    "    # Concatenate all batches into single tensors\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy(all_preds, all_labels)\n",
    "    train_mDice = mDice(all_preds, all_labels)\n",
    "    \n",
    "    return running_loss / len(loader), train_accuracy, train_mDice\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct, total, running_loss = 0, 0, 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Store predictions and labels as tensors\n",
    "            all_preds.append(predicted.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    # Concatenate all batches into single tensors\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_accuracy = accuracy(all_preds, all_labels)\n",
    "    test_mDice = mDice(all_preds, all_labels)\n",
    "    \n",
    "    return running_loss / len(loader), test_accuracy, test_mDice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/11405 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 3761/11405 [05:16<15:15,  8.35batch/s]  "
     ]
    }
   ],
   "source": [
    "# Tracking metrics\n",
    "train_losses, test_losses = [], []\n",
    "train_accuracies, test_accuracies = [], []\n",
    "train_mdice, test_mdice = [], []\n",
    "\n",
    "# Main training Loop\n",
    "for epoch in range(2):\n",
    "    train_loss, train_accuracy, train_mDice = train(model, train_loader)\n",
    "    test_loss, test_accuracy, test_mDice = test(model, val_loader)\n",
    "\n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    train_mdice.append(train_mDice)\n",
    "    test_mdice.append(test_mDice)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Train mDice: {train_mDice:.4f} | Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}, Test mDice: {test_mDice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Plot Results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# mDice Plot\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(train_mdice, label='Train mDice')\n",
    "plt.plot(test_mdice, label='Test mDice')\n",
    "plt.title('mDice Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
