# 2025-03-14 - Practical 2
## dataset
https://paperswithcode.com/dataset/fashionpedia

https://huggingface.co/datasets/detection-datasets/fashionpedia

https://docs.ultralytics.com/tasks/segment/#val

## libraries

- pytorch: tensors, cuda, training loop, optimizers, some models
- torchvision: transforms, some models
- ultralytics: YOLO, for comparison
- huggingface: datasets, some models

## proposed initial steps

###  0. analyze dataset
---
- get statistics and visualizations of the dataset
- create hypotheses about results

### 1. research models/methods
---
- choose the right dependencies
- decide which 3 models we will use

### 2. setup
---
- create src directory
  - set up models.py, experiment_configs.py, etc.
- install dependencies and create pip requirements.txt

### 3. write vanilla training notebook
---
- for each model
  - load data
  - train (1 epoch, few steps)
  - evaluate
  - save results

### 4. run on hardware
---
- set up vast.ai
- run full-sized training once, vanilla

### 5. design experiments (the meat)
---
- design experiments_configs.py with different settings
- expand training notebook
- YOLO comparison (use the same results/metrics, but run in a different notebook)

### 6. analyze results
---
- compare results
  - use mDice, accuracy
  - excluding background
- generate visualizations
- write up
  - also look into state of the art

## notes
- steps 0, 1, and 2 can be done in parallel
- step 3 is dependent on step 2
- the remaining steps are sequential
- except for hyperparameters, everything is pre-training changes (e.g. modifying data)
- let's use fewer epochs
  - early stopping??

## research questions
1. non-grid search on learning rate and batch size
  - same rq, but different experiment runs
2. augmentation
  - nothing
  - leave one out
  - all
3. image resolution
  - is it parameterized by the architecture?
  - is it preprocessing, e.g. a pytorch layer?
---
choose best network 

4. imbalanced data (discarding overrepresented classes)
5. yolo experiment comparison