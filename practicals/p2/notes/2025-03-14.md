# 2025-03-14 - Practical 2
## dataset
https://paperswithcode.com/dataset/fashionpedia

https://huggingface.co/datasets/detection-datasets/fashionpedia

https://docs.ultralytics.com/tasks/segment/#val

## libraries

- pytorch: tensors, cuda, training loop, optimizers, some models
- torchvision: transforms, some models
- ultralytics: YOLO, for comparison
- huggingface: datasets, some models

## proposed initial steps

###  0. analyze dataset
---
- get statistics and visualizations of the dataset
- create hypotheses about results

### 1. research models/methods
---
- choose the right dependencies
- decide which 3 models we will use

### 2. setup
---
- create src directory
  - set up models.py, experiment_configs.py, etc.
- install dependencies and create pip requirements.txt

### 3. write vanilla training notebook
---
- for each model
  - load data
  - train (1 epoch, few steps)
  - evaluate
  - save results

### 4. run on hardware
---
- set up vast.ai
- run full-sized training once, vanilla

### 5. design experiments (the meat)
---
- design experiments_configs.py with different settings
- expand training notebook

### 6. analyze results
---
- compare results
- generate visualizations
- write up

## notes
- 

## assignments
- 

## deadlines
- 
